{"cells":[{"cell_type":"markdown","metadata":{"id":"uKGwfFT9GJDC"},"source":["# Lesson 13.1 深度学习建模目标与性能评估理论"]},{"cell_type":"markdown","metadata":{"id":"XbLUolq7GJDK"},"source":["&emsp;&emsp;从Lesson 13起，我们讲开始系统介绍深度学习建模理论，以及建模过程中的优化方法。"]},{"cell_type":"markdown","metadata":{"id":"Oi57OsbGGJDN"},"source":["## 一、在Jupyter初始化过程中自动加载常用包的设置方法"]},{"cell_type":"markdown","metadata":{"id":"NmOWV8yFGJDN"},"source":["&emsp;&emsp;在每一节课程的开头，我们都要导入常用包，由于这项工作重复而固定，因此我们也可以通过配置jupyter（准确来说应该是ipython）的startup文件，来使得每次新创建一个ipy文件时，都能够自动加载配置好的包，从而就能免去每节开头导入包的相关操作。（所以说，懒惰是推动技术进步的不竭动力。）相关方法如下："]},{"cell_type":"markdown","metadata":{"id":"fikvfI-nGJDO"},"source":["- 找到startup文件夹"]},{"cell_type":"markdown","metadata":{"id":"k_UbfAmgGJDO"},"source":["&emsp;&emsp;在当前用户主目录下，找到`.ipython`文件夹，然后进入到`profile_default`文件夹内，并找到`startup`文件夹。此处如果profile_default内没有startup文件夹，自己新建一个即可。"]},{"cell_type":"markdown","metadata":{"id":"QHsqNQRSGJDP"},"source":["<img src=\"https://i.loli.net/2021/02/21/8ZXCNOWezrHoaEy.jpg\" alt=\"55\" style=\"zoom:30%;\" />"]},{"cell_type":"markdown","metadata":{"id":"qvWF5gSZGJDP"},"source":["- 创建start.py文件"]},{"cell_type":"markdown","metadata":{"id":"JyazeXhoGJDQ"},"source":["&emsp;&emsp;接下来，在startup文件夹内，创建一个start.py文件。关于创建py文件的方法此前介绍过，此处我们只需先创建一个txt文件，然后将其名称和后缀改为start.py即可。"]},{"cell_type":"markdown","metadata":{"id":"AdGJBEs5GJDQ"},"source":["<img src=\"https://i.loli.net/2021/02/21/pS81Ht6vDUfd7L4.jpg\" alt=\"56\" style=\"zoom:30%;\" />"]},{"cell_type":"markdown","metadata":{"id":"EXjEg72xGJDR"},"source":["<img src=\"https://i.loli.net/2021/02/21/aRSxEuTCOlo9UHV.jpg\" alt=\"57\" style=\"zoom:50%;\" />"]},{"cell_type":"markdown","metadata":{"id":"XVMtdfIEGJDR"},"source":["- 输入每次初始化时需要执行的代码"]},{"cell_type":"markdown","metadata":{"id":"tCHNBFzvGJDR"},"source":["&emsp;&emsp;在start.py中输入每次初始化时导入包的代码，相关代码如下："]},{"cell_type":"raw","metadata":{"id":"_hWc2HMvGJDS"},"source":["# 随机模块\n","import random\n","\n","# 时间模块\n","import time\n","\n","# 数学模块\n","import math\n","\n","# 绘图模块\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","\n","# numpy\n","import numpy as np\n","\n","# pandas\n","import pandas as pd\n","\n","# pytorch\n","import torch\n","from torch import nn,optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset,TensorDataset,DataLoader\n","\n","# 自定义模块\n","from torchLearning import *\n","\n","# 导入以下包从而使得可以在jupyter中的一个cell输出多个结果\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\""]},{"cell_type":"markdown","metadata":{"id":"gbHh6MkkGJDT"},"source":["> 注意，上述cell是raw模式，不是代码模式。"]},{"cell_type":"markdown","metadata":{"id":"JF5nToVpGJDT"},"source":["我们可以使用记事本打开.py文件，然后复制上述内容然后保存。"]},{"cell_type":"markdown","metadata":{"id":"YA8rwgmmGJDT"},"source":["<img src=\"https://i.loli.net/2021/02/21/bXWaUhZTJMG7PQz.jpg\" alt=\"58\" style=\"zoom:30%;\" />"]},{"cell_type":"markdown","metadata":{"id":"9bS8OxwkGJDU"},"source":["- 重启ipy，检测是否生效"]},{"cell_type":"markdown","metadata":{"id":"UfXMQmBuGJDU"},"source":["然后需要重启ipy kernel，此处重启的方法也非常简单，只需在jupyter中先将当前kernel关闭"]},{"cell_type":"markdown","metadata":{"id":"4ifq1iswGJDU"},"source":["<img src=\"https://i.loli.net/2021/02/21/ORbHfrPWxASEMvZ.jpg\" alt=\"59\" style=\"zoom:33%;\" />"]},{"cell_type":"markdown","metadata":{"id":"aeKKhmXVGJDV"},"source":["在最左侧栏中选择文件目录的下一个按钮，查看当前运行的kernel和terminal，找到Lesson 13.1（当前打开的ipy文件），然后点击SHUT DOWN。此时当前页面右上角就会显示为No Kernel，点击选择Python 3，就相当于重启了当前jupyter中的Python kernel。"]},{"cell_type":"markdown","metadata":{"id":"BIcvuw_jGJDV"},"source":["<img src=\"https://i.loli.net/2021/02/21/VdMP52LoZIjEAD4.jpg\" alt=\"60\" style=\"zoom:33%;\" />"]},{"cell_type":"markdown","metadata":{"id":"ZZZR4DtkGJDV"},"source":["<img src=\"https://i.loli.net/2021/02/21/aNnWuFBRtKeZA6y.jpg\" alt=\"61\" style=\"zoom:33%;\" />"]},{"cell_type":"markdown","metadata":{"id":"Li7ZQkYHGJDV"},"source":["当然，也可以直接点击重启按钮，重启当前jupyter kernel。"]},{"cell_type":"markdown","metadata":{"id":"k85SWLOtGJDW"},"source":["<img src=\"https://i.loli.net/2021/02/26/AqXGEdvliUw154t.jpg\" alt=\"65\" style=\"zoom:50%;\" />"]},{"cell_type":"markdown","metadata":{"id":"REghrZubGJDW"},"source":["- 测试初始化配置是否生效"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x8cGP3TrGJDX","outputId":"c28a8011-2da6-4801-ab89-dfe630411130"},"outputs":[{"data":{"text/plain":["tensor(1)"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["torch.tensor(1)"]},{"cell_type":"markdown","metadata":{"id":"oeO-_s8vGJDa"},"source":["至此也验证了初始化设置成功，每次创建jupyter文件时都将自动导入我们设置好的第三方库，即可免去每节开始的导包代码。"]},{"cell_type":"code","source":["# 随机模块\n","import random\n","\n","# 绘图模块\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","\n","# numpy\n","import numpy as np\n","\n","# pytorch\n","import torch\n","from torch import nn,optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset,TensorDataset,DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# 自定义模块\n","from torchLearning import *\n","\n","# 导入以下包从而使得可以在jupyter中的一个cell输出多个结果\n","from IPython.core.interactiveshell import InteractiveShell\n","InteractiveShell.ast_node_interactivity = \"all\""],"metadata":{"id":"STApiKDLHBfq","executionInfo":{"status":"ok","timestamp":1651852981893,"user_tz":-120,"elapsed":5569,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"998rwnplGJDa"},"source":["## 二、机器学习目标与模型评估方法"]},{"cell_type":"markdown","metadata":{"id":"XInC8wFNGJDb"},"source":["&emsp;&emsp;在了解深度学习基本模型的概念与实现方法后，接下来，我们将详细探讨深度学习模型优化的常用方法。从上一课的实验中不难发现，要把一个模型“建好”已是不容易，而要想办法把模型的效果进行提升，如果没有基础理论支持和方法论工具，优化过程无异于盲人摸象。因此，本节课将从建模的根本目标出发，围绕模型优化的基本概念和核心理论进行全面梳理，并在此基础之上介绍相关实践方法，逐渐拨开模型优化面前的迷雾。"]},{"cell_type":"markdown","metadata":{"id":"Ue_EDOqtGJDb"},"source":["&emsp;&emsp;我们经常会对模型的好坏优劣进行评估，Lesson 12中我们也使用准确率、MSE等指标评估建模结果，看起来模型评估是围绕某项指标在进行评估，指标好模型就好，指标不好模型就不好，其实并不完全如此。要了解模型的性能其实并不简单，固然我们会使用某些指标去进行模型评估，但其实指标也只是我们了解模型性能的途径而不是模型性能本身。而要真实、深刻的评判模型性能，就必须首先了解机器学习的建模目标，并在此基础之上熟悉我们判断模型是否能够完成目标的一些方法，当然，只有真实了解的模型性能，我们才能进一步考虑如何提升模型性能。因此，在正式讲解模型优化方法之前，我们需要花些时间讨论机器学习算法的建模目标、机器学习算法为了能够达到目标的一般思路，以及评估模型性能的手段，也就是模型评估指标。"]},{"cell_type":"markdown","metadata":{"id":"QJzwIHtRGJDb"},"source":["&emsp;&emsp;无论是机器学习还是传统的统计分析模型，核心使命就是探索数字规律，而有监督学习则是希望在探索数字规律的基础上进一步对未来进行预测，当然，在数字的世界，这个预测未来，也就是预测未来某项事件的某项数值指标，如某地区未来患病人次、具备某种数字特征的图片上的动物是哪一类，此处的未来也并非指绝对意义上的以后的时间，而是在模型训练阶段暂时未接触到的数据。正是因为模型有了在未知标签情况下进行预判的能力，有监督学习才有了存在的价值，但我们知道，基本上所有的模型，都只能从以往的历史经验当中进行学习，也就是在以往的、已经知道的数据集上进行训练（如上述利用已知数据集进行模型训练，如利用过往股票数据训练时间序列模型），这里的核心矛盾在于，在以往的数据中提取出来的经验（也就是模型），怎么证明能够在接下来的数据中也具备一定的预测能力呢？或者说，要怎么训练模型，才能让模型在未知的数据集上也拥有良好的表现呢？"]},{"cell_type":"markdown","metadata":{"id":"9nCu4-gsGJDc"},"source":["&emsp;&emsp;目的相同，但在具体的实现方法上，传统的数理统计分析建模和机器学习采用了不同的解决方案。"]},{"cell_type":"markdown","metadata":{"id":"PIEF6cDDGJDc"},"source":["&emsp;&emsp;首先，在统计分析领域，我们会假设现在的数据和未来的数据其实都属于某个存在但不可获得的总体，也就是说，现在和未来的数据都是从某个总体中抽样而来的，都是这个总体的样本。而正式因为这些数据属于同一个总体，因此具备某些相同的规律，而现在挖掘到的数据规律也就在某些程度上可以应用到未来的数据当中去，不过呢，不同抽样的样本之间也会有个体之间的区别，另外模型本身也无法完全捕获规律，而这些就是误差的来源。"]},{"cell_type":"markdown","metadata":{"id":"0VnUwAUEGJDc"},"source":["&emsp;&emsp;虽然样本和总体的概念是统计学概念，但样本和总体的概念所假设的前后数据的“局部规律一致性”，却是所有机器学习建模的基础。试想一下，如果获取到的数据前后描绘的不是一件事情，那么模型训练也就毫无价值（比如拿着A股走势预测的时间序列预测某地区下个季度患病人次）。因此，无论是机器学习所强调的从业务角度出发，要确保前后数据描述的一致性，还是统计分析所强调的样本和总体的概念，都是建模的基础。"]},{"cell_type":"markdown","metadata":{"id":"FkUwbBntGJDd"},"source":["&emsp;&emsp;在有了假设基础之后，统计分析就会利用一系列的数学方法和数理统计工具去推导总体的基本规律，也就是变量的分布规律和一些统计量的取值，由于这个过程是通过已知的样本去推断未知的总体，因此会有大量的“估计”和“检验”，在确定了总体的基本分布规律之后，才能够进一步使用统计分析模型构建模型（这也就是为什么在数理统计分析领域，构建线性回归模型需要先进行一系列的检验和变换的原因），当然，这些模型都是在总体规律基础之上、根据样本具体的数值进行的建模，我们自然有理由相信这些模型对接下来仍然是从总体中抽样而来的样本还是会具备一定的预测能力，这也就是我们对统计分析模型“信心”的来源。简单来说，就是我们通过样本推断总体的规律，然后结合总体的规律和样本的数值构建模型，由于模型也描绘了总体规律，所以模型对接下来从总体当中抽样而来的数据也会有不错的预测效果，这个过程我们可以通过下图来进行表示。"]},{"cell_type":"markdown","metadata":{"id":"G7mwpottGJDd"},"source":["<img src=\"https://i.loli.net/2021/02/05/KIpJCDyq9VQoliN.jpg\" alt=\"37\" style=\"zoom:40%;\" />"]},{"cell_type":"markdown","metadata":{"id":"8YXlvMnDGJDd"},"source":["&emsp;&emsp;而对于机器学习来说，并没有借助“样本-总体”的基本理论，而是简单的采用了一种后验的方法来判别模型有效性，前面说到，我们假设前后获取的数据拥有规律一致性，但数据彼此之间又略有不同，为了能够在捕捉规律的同时又能考虑到“略有不同”所带来的误差，机器学习会把当前能获取到的数据划分成训练集(trainSet)和测试集(testSet)，在训练集上构建模型，然后带入测试集的数据，观测在测试集上模型预测结果和真实结果之间的差异。这个过程其实就是在模拟获取到真实数据之后模型预测的情况，此前说到，模型能够在未知标签的数据集上进行预测，就是模型的核心价值，此时的测试集就是用于模拟未来的未知标签的数据集。如果模型能够在测试集上有不错的预测效果，我们就“简单粗暴”的认为模型可以在真实的未来获取的未知数据集上有不错的表现。其一般过程可以由下图表示。"]},{"cell_type":"markdown","metadata":{"id":"yT6yjmYOGJDe"},"source":["<img src=\"https://i.loli.net/2021/02/05/fGzPxCQ1qoOZuFs.jpg\" alt=\"38\" style=\"zoom:40%;\" />"]},{"cell_type":"markdown","metadata":{"id":"7OJLuwB9GJDe"},"source":["&emsp;&emsp;虽然对比起数理统计分析，机器学习的证明模型有效性的过程更加“简单”，毕竟只要一次“模拟”成功，我们就认为模型对未来的数据也拥有判别效力，但这种“简单”的处理方式却非常实用，可以说，这是一种经过长期实践被证明的行之有效的方法。这也是为什么机器学习很多时候也被认为是实证类的方法，而在以后的学习中，我们也将了解到，机器学习有很多方法都是“经验总结的结果”。相比数理统计分析，确实没有“那么严谨”，但更易于理解的理论和更通用的方法，却使得机器学习可以在更为广泛的应用场景中发挥作用。（当然，负面影响却是，机器学习在曾经的很长一段时间内并不是主流的算法。）"]},{"cell_type":"markdown","metadata":{"id":"_e8a0igqGJDe"},"source":["&emsp;&emsp;据此，我们称模型在训练集上误差称为训练误差，在测试集上的误差称为泛化误差，不过毕竟在测试集上进行测试还只是模拟演习，我们采用模型的泛化能力来描述模型在未知数据上的判别能力，当然泛化能力无法准确衡量（未知的数据还未到来，到来的数据都变成了已知数据），我们只能通过模型在训练集和测试集上的表现，判别模型泛化能力，当然，就像此前说的一样，最基本的，我们会通过模型在测试集上的表现来判断模型的泛化能力。"]},{"cell_type":"markdown","metadata":{"id":"6TPrXgNqGJDe"},"source":["## 三、手动实现训练集和测试集切分"]},{"cell_type":"markdown","metadata":{"id":"3kMQy3FiGJDf"},"source":["&emsp;&emsp;接下来我们开始实践模型评估过程，首先是对训练集和测试集的划分，我们尝试创建一个切分训练集和测试集的函数。"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"o7Or7t9LGJDf","executionInfo":{"status":"ok","timestamp":1651853969444,"user_tz":-120,"elapsed":229,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["def data_split(features, labels, rate=0.7):\n","    \"\"\"\n","    训练集和测试集切分函数\n","    \n","    :param features: 输入的特征张量\n","    :param labels：输入的标签张量\n","    :param rate：训练集占所有数据的比例\n","    :return Xtrain, Xtest, ytrain, ytest：返回特征张量的训练集、测试集，以及标签张量的训练集、测试集 \n","    \"\"\"\n","    num_examples = len(features)                              # 总数据量\n","    indices = list(range(num_examples))                       # 数据集行索引\n","    random.shuffle(indices)                                   # 乱序调整                     \n","    num_train = int(num_examples * rate)                      # 训练集数量 \n","    indices_train = torch.tensor(indices[: num_train])        # 在已经乱序的的indices中挑出前num_train数量的行索引值\n","    indices_test = torch.tensor(indices[num_train: ])         \n","    Xtrain = features[indices_train]                          # 训练集特征\n","    ytrain = labels[indices_train]                            # 训练集标签\n","    Xtest = features[indices_test]                            # 测试集特征\n","    ytest = labels[indices_test]                              # 测试集标签\n","    return Xtrain, Xtest, ytrain, ytest"]},{"cell_type":"markdown","metadata":{"id":"Qw8K-tchGJDg"},"source":["> &emsp;&emsp;一般来说，训练集和测试集可以按照8：2或7：3比例进行划分。在进行数据划分的过程中，如果测试集划分数据过多，参与模型训练的数据就会相应减少，而训练数据不足则会导致模型无法正常训练、损失函数无法收敛、模型过拟合等问题，但如果反过来测试集划分数据过少，则无法代表一般数据情况测试模型是否对未知数据也有很好的预测作用。因此，根据经验，我们一般来说会按照8：2或7：3比例进行划分。      \n","&emsp;&emsp;看到这里，相信肯定有小伙伴觉得根据所谓的“经验”来定数据集划分比例不太严谨，有没有一种方法能够“精准”的确定什么划分比例最佳呢？例如通过类似最小二乘法或者梯度下降这类优化算法来计算划分比例？各位同学可以尝试着进行思考，并给出自己的答案。课程中将在下一节介绍参数和超参数时给出详细解答。         \n","&emsp;&emsp;值得一提的是，在机器学习领域，充斥着大量的“经验之谈”或者“约定俗成”的规则，一方面这些经验为建模提供了诸多便捷、也节省了很多算力，但另一方面，通过经验来决定影响模型效果的一些“超参数”取值的不严谨的做法，也被数理统计分析流派所诟病。"]},{"cell_type":"markdown","metadata":{"id":"opB0JwyMGJDg"},"source":["接下来，测试函数性能"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dLptPh5VGJDh","outputId":"7128e5c8-9d7c-4a72-b6f1-705f56ffd851"},"outputs":[{"data":{"text/plain":["tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["f = torch.arange(10)                # 创建特征0-9\n","f"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MnAh242RGJDh","outputId":"0f902356-c58a-42c9-a81c-98a76eb8d080"},"outputs":[{"data":{"text/plain":["tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["l = torch.arange(1, 11)             # 创建标签1-10，保持和特征+1的关系\n","l"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jN2N-u0JGJDh","outputId":"59732cb3-dd2d-4dc6-f902-9cee744e146a"},"outputs":[{"data":{"text/plain":["(tensor([1, 6, 4, 5, 8, 3, 0]),\n"," tensor([9, 7, 2]),\n"," tensor([2, 7, 5, 6, 9, 4, 1]),\n"," tensor([10,  8,  3]))"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["data_split(f, l)"]},{"cell_type":"markdown","metadata":{"id":"2T9Vu8vVGJDi"},"source":["接下来，还是在上一节课的内容上，尝试带入训练集进行建模，利用测试集评估模型建模效果"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ibh0VxFlGJDi","executionInfo":{"status":"ok","timestamp":1651857810537,"user_tz":-120,"elapsed":238,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"1aa7f625-cc8d-49f2-ad0a-6029175ebb94"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f023ee04050>"]},"metadata":{},"execution_count":3}],"source":["# 设置随机数种子\n","torch.manual_seed(420)   \n","\n","# 生成回归类数据集\n","features, labels = tensorGenReg()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yZep4TvPGJDi","outputId":"8de267bb-b5cd-43b6-a1d6-3dd784cb48c0"},"outputs":[{"data":{"text/plain":["tensor([[-0.0070,  0.5044,  1.0000],\n","        [ 0.6704, -0.3829,  1.0000],\n","        [ 0.0302,  0.3826,  1.0000],\n","        ...,\n","        [-0.9164, -0.6087,  1.0000],\n","        [ 0.7815,  1.2865,  1.0000],\n","        [ 1.4819,  1.1390,  1.0000]])"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["features"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3eBViwpAGJDj","executionInfo":{"status":"ok","timestamp":1651857811985,"user_tz":-120,"elapsed":222,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"081171d1-3a07-4cf6-c8d0-826c555e0cd8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f023ee04050>"]},"metadata":{},"execution_count":4}],"source":["torch.manual_seed(420) \n","\n","# 初始化数据\n","features, labels = tensorGenReg()\n","\n","# 切分训练集和测试集\n","Xtrain, Xtest, ytrain, ytest = data_split(features, labels)\n","\n","# 初始化核心参数\n","batch_size = 10                                # 小批的数量\n","lr = 0.03                                      # 学习率\n","num_epochs = 5                                 # 训练过程遍历几次数据\n","w = torch.zeros(3, 1, requires_grad = True)    # 随机设置初始权重\n","\n","# 参与训练的模型方程\n","net = linreg                                   # 使用回归方程\n","loss = MSE_loss                                # 均方误差的一半作为损失函数\n","\n","# 模型训练过程\n","for epoch in range(num_epochs):\n","    for X, y in data_iter(batch_size, Xtrain, ytrain):\n","        l = loss(net(X, w), y)\n","        l.backward()\n","        sgd(w, lr)"]},{"cell_type":"markdown","metadata":{"id":"hqQYWpU3GJDj"},"source":["查看训练结果"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RsAEf7WGJDk","executionInfo":{"status":"ok","timestamp":1651857831261,"user_tz":-120,"elapsed":225,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"80da1a81-7691-4663-defa-a08bc83bbb74"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 2.0003],\n","        [-0.9998],\n","        [ 1.0008]], requires_grad=True)"]},"metadata":{},"execution_count":5}],"source":["w"]},{"cell_type":"markdown","metadata":{"id":"vLNbIxqNGJDk"},"source":["查看模型在训练集、测试集上的MSE"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Vy6J5J6GJDk","executionInfo":{"status":"ok","timestamp":1651857834065,"user_tz":-120,"elapsed":221,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"59c018fb-c143-46b6-a3a4-b5a8b4a422af"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.0001, grad_fn=<DivBackward0>)"]},"metadata":{},"execution_count":6}],"source":["MSE_loss(torch.mm(Xtrain, w), ytrain)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gabM9GUGGJDl","executionInfo":{"status":"ok","timestamp":1651857836098,"user_tz":-120,"elapsed":229,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"94a75811-9688-4318-804e-517485dae8a5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.0001, grad_fn=<DivBackward0>)"]},"metadata":{},"execution_count":7}],"source":["MSE_loss(torch.mm(Xtest, w), ytest)"]},{"cell_type":"markdown","metadata":{"id":"YroC00UYGJDl"},"source":["至此，我们就完成了一整个从数据集划分，到训练集训练，再到测试集上测试模型性能的一整个流程。"]},{"cell_type":"markdown","metadata":{"id":"vIvxsCbOGJDl"},"source":["## 四、Dataset和DataLoader基本使用方法与数据集切分函数"]},{"cell_type":"markdown","metadata":{"id":"1WNQVGjRGJDl"},"source":["&emsp;&emsp;接下来，我们尝试使用PyTorch原生库来实现上述功能，不过这个实现过程略显复杂，首先我们需要了解Dataset和DataLoader的基本使用方法。"]},{"cell_type":"markdown","metadata":{"id":"ZIpSdHScGJDm"},"source":["### 1.Dataset和DataLoader的基本使用方法"]},{"cell_type":"markdown","metadata":{"id":"Ys8Ni6erGJDm"},"source":["- random_split随机切分函数"]},{"cell_type":"markdown","metadata":{"id":"a97rcoewGJDm"},"source":["&emsp;&emsp;首先，在PyTorch的`torch.utils.data`中，提供了`random_split`函数可用于数据集切分。"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"vYkkk_VCGJDn","executionInfo":{"status":"ok","timestamp":1651858016274,"user_tz":-120,"elapsed":216,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["from torch.utils.data import random_split"]},{"cell_type":"markdown","metadata":{"id":"mXqWLYXcGJDn"},"source":["简单测试函数功能"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0IZSw1UmGJDn","executionInfo":{"status":"ok","timestamp":1651858018097,"user_tz":-120,"elapsed":459,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"873e69d8-71ab-4bf7-d60b-9f1bb6cfabc7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0,  1,  2],\n","        [ 3,  4,  5],\n","        [ 6,  7,  8],\n","        [ 9, 10, 11]])"]},"metadata":{},"execution_count":9}],"source":["t = torch.arange(12).reshape(4, 3)\n","t"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cIHsQkQPGJDo","executionInfo":{"status":"ok","timestamp":1651858035114,"user_tz":-120,"elapsed":222,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"13923f94-1cb9-4978-8467-a5cbbd50824b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<torch.utils.data.dataset.Subset at 0x7f0229568610>,\n"," <torch.utils.data.dataset.Subset at 0x7f0229568790>]"]},"metadata":{},"execution_count":10}],"source":["random_split(t, [2, 2])         # 输入切分的每部分数据集数量"]},{"cell_type":"markdown","metadata":{"id":"HylQalD-GJDo"},"source":["根据生成结果可知，`random_split`函数其实生成了生成器切分结果的生成器，并不是和此前定义的函数一样，直接切分数据后返回。当然这也符合utils.data模块主要生成映射式和迭代式对象的一般规定。"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"2xCeHyFpGJDo","executionInfo":{"status":"ok","timestamp":1651861778952,"user_tz":-120,"elapsed":214,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["train, test = random_split(t, [2, 2])"]},{"cell_type":"markdown","metadata":{"id":"PZUNyiY9GJDo"},"source":["使用print函数查看生成器内容"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYAEKpKNGJDo","executionInfo":{"status":"ok","timestamp":1651861782339,"user_tz":-120,"elapsed":686,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"9cb5fc61-f8b1-488e-8cf9-ee1100244e7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([ 9, 10, 11]) tensor([0, 1, 2])\n","tensor([3, 4, 5]) tensor([6, 7, 8])\n"]}],"source":["for tr, te in random_split(t, [2, 2]):\n","    print(tr, te)"]},{"cell_type":"markdown","metadata":{"id":"rfTtY0vgGJDp"},"source":["- Dataset和Dataloader"]},{"cell_type":"markdown","metadata":{"id":"MM7v_vGGGJDp"},"source":["&emsp;&emsp;由于在大多数调库建模过程中，我们都是先通过创建Dataset的子类并将数据保存为该子类类型，然后再使用DataLoader进行数据载入，因此更为通用的做法是先利用Dataset和DatasetLoader这两个类进行数据的读取、预处理和载入，然后再使用random_split函数进行切分。      \n","&emsp;&emsp;再次强调，Dataset类主要负责数据类的生成，在PyTorch中，所有数据集都是Dataset的子类；而DatasetLoader类则是加载模型训练的接口，二者基本使用流程如下："]},{"cell_type":"markdown","metadata":{"id":"hYnIiAwhGJDp"},"source":["![49](https://i.loli.net/2021/02/07/LQsueTFV9bDlKx1.jpg)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"jloHwoRCGJDp","executionInfo":{"status":"ok","timestamp":1651861517174,"user_tz":-120,"elapsed":228,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader"]},{"cell_type":"markdown","metadata":{"id":"C0MDpcOOGJDq"},"source":["- 创建数据类"]},{"cell_type":"markdown","metadata":{"id":"bZy1TP56GJDq"},"source":["&emsp;&emsp;根据此前描述，PyTorch中所有的数据都是Dataset的子类，换而言之就是在使用PyTorch建模训练数据时，需要创建一个和数据集对应的类来表示该数据集，此前我们使用的TensorDataset函数其实就是一个简单的类型转化函数，将数据统一转化为“TensorDataset”类然后带入模型进行计算。"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"n3WylVRzGJDq","executionInfo":{"status":"ok","timestamp":1651861789001,"user_tz":-120,"elapsed":703,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["features, labels = tensorGenReg(bias=False)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sGQCHtu_GJDq","executionInfo":{"status":"ok","timestamp":1651861791525,"user_tz":-120,"elapsed":573,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"5095066b-56ac-4490-c375-b5c99ee2230e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.0620,  0.9777, -0.5188],\n","        [ 1.5322,  0.9412, -1.5458],\n","        [-1.0757,  0.3685, -0.3861],\n","        ...,\n","        [-0.4219,  1.8953,  0.2729],\n","        [ 1.5083,  2.4858,  1.2882],\n","        [ 0.3493,  1.4100,  1.3258]])"]},"metadata":{},"execution_count":15}],"source":["features"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"BlIakBaEGJDr","executionInfo":{"status":"ok","timestamp":1651861793542,"user_tz":-120,"elapsed":557,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["data = TensorDataset(features, labels)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sEUPhUP2GJDr","executionInfo":{"status":"ok","timestamp":1651861794323,"user_tz":-120,"elapsed":3,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"e00a35dc-b900-4839-806a-81b62cb1ddc2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.utils.data.dataset.TensorDataset at 0x7f022798d390>"]},"metadata":{},"execution_count":17}],"source":["data"]},{"cell_type":"markdown","metadata":{"id":"hJTH4X93GJDr"},"source":["而TensorDataset其实使用面较窄，最直接的限制就是该函数只能将张量类型转化为TensorDataset类"]},{"cell_type":"code","execution_count":18,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"colab":{"base_uri":"https://localhost:8080/","height":340},"id":"6AdQrNvYGJDr","executionInfo":{"status":"error","timestamp":1651861803146,"user_tz":-120,"elapsed":229,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"1784eab6-d2ab-40de-c01e-fa5a54b113e4"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-a22ab840f41d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"]}],"source":["TensorDataset([1,2], 1)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"jZ6FPxbDGJDs","executionInfo":{"status":"ok","timestamp":1651861807488,"user_tz":-120,"elapsed":205,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["TensorDataset?"]},{"cell_type":"markdown","metadata":{"id":"dckZ7nizGJDs"},"source":["更加通用的数据读取方法则是手动创建一个继承自torch.utils.data.dataset的数据类，用来作为当前数据的表示。例如Lesson 11中的乳腺癌数据，通过如下方式进行读取"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"6D5FV7gFGJDt","executionInfo":{"status":"ok","timestamp":1651861813913,"user_tz":-120,"elapsed":579,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["from sklearn.datasets import load_breast_cancer as LBC\n","data = LBC()"]},{"cell_type":"markdown","metadata":{"id":"mF4bz-PRGJDt"},"source":["简单查看data数据集"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pPkJziM8GJDt","executionInfo":{"status":"ok","timestamp":1651861824290,"user_tz":-120,"elapsed":217,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"965c8b28-64f4-4005-8ffe-918a255a8436"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n","        1.189e-01],\n","       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n","        8.902e-02],\n","       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n","        8.758e-02],\n","       ...,\n","       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n","        7.820e-02],\n","       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n","        1.240e-01],\n","       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n","        7.039e-02]])"]},"metadata":{},"execution_count":21}],"source":["data.data          # 返回数据集的特征数组"]},{"cell_type":"code","execution_count":22,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"colab":{"base_uri":"https://localhost:8080/"},"id":"uyfgOH4CGJDt","executionInfo":{"status":"ok","timestamp":1651861826881,"user_tz":-120,"elapsed":331,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"0babffe0-1701-4243-fe2d-7b6b9cc63520"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n","       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n","       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n","       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n","       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n","       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n","       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n","       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n","       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n","       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n","       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n","       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n","       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n","       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n","       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n","       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"]},"metadata":{},"execution_count":22}],"source":["data.target        # 返回数据集的标签数组  "]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XNqemWI4GJDu","executionInfo":{"status":"ok","timestamp":1651861832568,"user_tz":-120,"elapsed":201,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"d4b4c622-2f73-47ec-b377-5e20a9c989cf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["569"]},"metadata":{},"execution_count":23}],"source":["len(data.data)     # 返回数据集总个数"]},{"cell_type":"markdown","metadata":{"id":"y0DiFJ1CGJDu"},"source":["&emsp;&emsp;接下来，创建一个用于表示该数据集的Dataset的子类。在创建Dataset的子类过程中，必须要重写__getitem__方法和__len__方法，其中__getitem__方法返回输入索引后对应的特征和标签，而__len__方法则返回数据集的总数据个数。当然，在必须要进行的__init__初始化过程中，我们也可输入可代表数据集基本属性的相关内容，包括数据集的特征、标签、大小等等，视情况而定。"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"wr29sFJ_GJDu","executionInfo":{"status":"ok","timestamp":1651861926289,"user_tz":-120,"elapsed":216,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["class LBCDataset(Dataset):\n","    def __init__(self,data):                       # 创建该类时需要输入sklearn导入的数据集\n","        self.features = data.data                  # features属性返回数据集特征\n","        self.labels = data.target                  # labels属性返回数据集标签\n","        self.lens = len(data.data)                 # lens属性返回数据集大小\n","\n","    def __getitem__(self, index):\n","        # 调用该方法时需要输入index数值，方法最终返回index对应的特征和标签\n","        return self.features[index,:],self.labels[index]    \n","\n","    def __len__(self):\n","        # 调用该方法不需要输入额外参数，方法最终返回数据集大小\n","        return self.lens"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"lZ5Ydk-8GJDu","executionInfo":{"status":"ok","timestamp":1651861941689,"user_tz":-120,"elapsed":204,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["data = LBC()\n","LBC_data = LBCDataset(data)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QKoXQDdrGJDv","executionInfo":{"status":"ok","timestamp":1651861946420,"user_tz":-120,"elapsed":214,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"12cc3168-ff9f-4d51-ccba-0bfca8bdb8a7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n","        1.189e-01],\n","       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n","        8.902e-02],\n","       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n","        8.758e-02],\n","       ...,\n","       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n","        7.820e-02],\n","       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n","        1.240e-01],\n","       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n","        7.039e-02]])"]},"metadata":{},"execution_count":26}],"source":["LBC_data.features"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-FfPHvEnGJDv","executionInfo":{"status":"ok","timestamp":1651861948435,"user_tz":-120,"elapsed":251,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"c625e3b3-3ccf-49f2-8703-626ecf8b09df"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["569"]},"metadata":{},"execution_count":27}],"source":["LBC_data.lens"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwMSG2x0GJDv","executionInfo":{"status":"ok","timestamp":1651861953761,"user_tz":-120,"elapsed":205,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"8ae2ac4c-8d52-4e94-8452-8b4e7c0ab649"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n","        1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n","        4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n","        2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n","        1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02]), 0)"]},"metadata":{},"execution_count":28}],"source":["# 查看第三条数据\n","LBC_data.__getitem__(2)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ObVdyaV0GJDw","executionInfo":{"status":"ok","timestamp":1651861956870,"user_tz":-120,"elapsed":199,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"ace6a111-8e85-4c62-ebe6-85c940dbe539"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n","       1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n","       4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n","       2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n","       1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02])"]},"metadata":{},"execution_count":29}],"source":["LBC_data.features[2]"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vQfNn5pLGJDw","executionInfo":{"status":"ok","timestamp":1651861961454,"user_tz":-120,"elapsed":200,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"058e9f38-a42f-4c20-9aab-152b540e5fb4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":30}],"source":["LBC_data.labels[2]"]},{"cell_type":"markdown","metadata":{"id":"SF4n0Q6kGJDw"},"source":["封装好的数据可以直接进行索引，并且能够返回实体结果"]},{"cell_type":"code","execution_count":31,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"colab":{"base_uri":"https://localhost:8080/"},"id":"VaHnlV5sGJDw","executionInfo":{"status":"ok","timestamp":1651861967573,"user_tz":-120,"elapsed":216,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"770a9e56-25a1-4893-a061-72069428eb92"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n","         1.189e-01],\n","        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n","         8.902e-02],\n","        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n","         8.758e-02],\n","        ...,\n","        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n","         7.820e-02],\n","        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n","         1.240e-01],\n","        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n","         7.039e-02]]),\n"," array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n","        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n","        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n","        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n","        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n","        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n","        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n","        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n","        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n","        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n","        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n","        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n","        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n","        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n","        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n","        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]))"]},"metadata":{},"execution_count":31}],"source":["LBC_data[:]"]},{"cell_type":"markdown","metadata":{"id":"JxoAM_txGJDx"},"source":["另外，我们可以使用random_split方法对其进行切分"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"DNMnqdlJGJDx","executionInfo":{"status":"ok","timestamp":1651862009802,"user_tz":-120,"elapsed":206,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["# 确定训练集、测试集大小，此处以7：3划分训练集和测试集\n","num_train = int(LBC_data.lens * 0.7)\n","num_test = LBC_data.lens - num_train"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mo56aQTZGJDx","executionInfo":{"status":"ok","timestamp":1651862017274,"user_tz":-120,"elapsed":218,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"5d58b1d2-2ffd-4169-d471-9608acbb5c71"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["398"]},"metadata":{},"execution_count":33},{"output_type":"execute_result","data":{"text/plain":["171"]},"metadata":{},"execution_count":33}],"source":["num_train            # 训练集个数\n","num_test             # 测试集个数"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"aMBVllaiGJDx","executionInfo":{"status":"ok","timestamp":1651862064883,"user_tz":-120,"elapsed":210,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["LBC_train, LBC_test = random_split(LBC_data, [num_train, num_test])"]},{"cell_type":"markdown","metadata":{"id":"RB9sUM0PGJDy"},"source":["注，此时切分的结果是一个映射式的对象，只有dataset和indices两个属性，其中dataset属性用于查看原数据集对象，indices属性用于查看切分后数据集的每一条数据的index（序号）。"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"Bz6lOwM0GJDy","executionInfo":{"status":"ok","timestamp":1651862076868,"user_tz":-120,"elapsed":237,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["LBC_train?"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"foKbIw7AGJDy","executionInfo":{"status":"ok","timestamp":1651862130398,"user_tz":-120,"elapsed":253,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"03b0c5c8-fd6f-4bb7-b454-e8b3cfc7ef4f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<__main__.LBCDataset at 0x7f022798df10>"]},"metadata":{},"execution_count":37}],"source":["LBC_train.dataset"]},{"cell_type":"markdown","metadata":{"id":"fK4xwhnVGJDz"},"source":["通过切分结果还原原始数据集"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-SiM2RoGJDz","executionInfo":{"status":"ok","timestamp":1651862132875,"user_tz":-120,"elapsed":235,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"1e58463a-b984-4aad-8401-61200ad6cf31"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":38}],"source":["LBC_train.dataset == LBC_data      # 还原原数据集"]},{"cell_type":"markdown","metadata":{"id":"ymlbIKPQGJDz"},"source":["在原始数据集中查找切分数据集"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"tA6tx1RhGJDz"},"outputs":[],"source":["LBC_train.indices"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HPLYMg1-GJD0","executionInfo":{"status":"ok","timestamp":1651862155707,"user_tz":-120,"elapsed":197,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"0895c314-92cd-470d-e2b0-3c7627d306ac"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[384, 475, 64, 490, 496, 136, 123, 300, 175, 342]"]},"metadata":{},"execution_count":40}],"source":["LBC_train.indices[:10]             # 抽取的训练集数据的index"]},{"cell_type":"markdown","metadata":{"id":"_VbypQyAGJD0"},"source":["当然，无论是迭代式生成数据还是映射式生成数据，都可以使用print查看数据"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1rv0vFv0GJD0","executionInfo":{"status":"ok","timestamp":1651862182311,"user_tz":-120,"elapsed":206,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"9a9200cd-5a47-4159-9dab-2413f1cd2f42"},"outputs":[{"output_type":"stream","name":"stdout","text":["(array([1.328e+01, 1.372e+01, 8.579e+01, 5.418e+02, 8.363e-02, 8.575e-02,\n","       5.077e-02, 2.864e-02, 1.617e-01, 5.594e-02, 1.833e-01, 5.308e-01,\n","       1.592e+00, 1.526e+01, 4.271e-03, 2.073e-02, 2.828e-02, 8.468e-03,\n","       1.461e-02, 2.613e-03, 1.424e+01, 1.737e+01, 9.659e+01, 6.237e+02,\n","       1.166e-01, 2.685e-01, 2.866e-01, 9.173e-02, 2.736e-01, 7.320e-02]), 1)\n"]}],"source":["for i in LBC_train:\n","    print(i)\n","    break"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aHre2og3GJD1","executionInfo":{"status":"ok","timestamp":1651862183792,"user_tz":-120,"elapsed":207,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"6c6c7960-5dbe-4cc0-b64c-3474e0049556"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([1.328e+01, 1.372e+01, 8.579e+01, 5.418e+02, 8.363e-02, 8.575e-02,\n","        5.077e-02, 2.864e-02, 1.617e-01, 5.594e-02, 1.833e-01, 5.308e-01,\n","        1.592e+00, 1.526e+01, 4.271e-03, 2.073e-02, 2.828e-02, 8.468e-03,\n","        1.461e-02, 2.613e-03, 1.424e+01, 1.737e+01, 9.659e+01, 6.237e+02,\n","        1.166e-01, 2.685e-01, 2.866e-01, 9.173e-02, 2.736e-01, 7.320e-02]), 1)"]},"metadata":{},"execution_count":42}],"source":["LBC_data.__getitem__(384)           # 验证是否是LBC_train的第一条数据"]},{"cell_type":"code","execution_count":43,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"colab":{"base_uri":"https://localhost:8080/"},"id":"QDmZRGSSGJD1","executionInfo":{"status":"ok","timestamp":1651862208912,"user_tz":-120,"elapsed":191,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"b3b9aa9d-710e-40a3-fff2-b4649b120bf0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n","       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0,\n","       1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n","       1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n","       1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n","       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n","       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n","       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n","       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n","       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n","       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n","       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n","       0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n","       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n","       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n","       0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n","       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n","       0, 0])"]},"metadata":{},"execution_count":43}],"source":["LBC_data[LBC_train.indices][1]"]},{"cell_type":"markdown","metadata":{"id":"iYWhRUceGJD1"},"source":["> 还是需要强调，虽然PyTorch的数据表示形式会略显复杂，但这是应对复杂大规模数据计算之必须，面对海量、非结构化数据，我们很难去查看一条条数据，而只能通过一些数据集的特性来探索数据信息。"]},{"cell_type":"markdown","metadata":{"id":"ZTzDB9UoGJD1"},"source":["&emsp;&emsp;然后使用DataLoader函数进行数据转化，由一般数据状态转化为“可建模”的状态。所谓“可建模”状态，指的是经过DataLoader处理的数据，不仅包含数据原始的数据信息，还包含数据处理方法信息，如调用几个线程进行训练、分多少批次等，DataLoader常用参数如下："]},{"cell_type":"markdown","metadata":{"id":"aaqLuMKJGJD2"},"source":["- batch_size:每次迭代输入多少数据，如果是小批量梯度下降，则输入的数据量就是小批量迭代过程中“小批”的数量      \n","- shuffle:是否需要先打乱顺序然后再进行小批量的切分，一般训练集需要乱序，而测试集乱序没有意义      \n","- num_worker:启动多少线程进行计算      \n"]},{"cell_type":"markdown","metadata":{"id":"iq03c8q0GJD2"},"source":["其他更多参数，将随着我们介绍的深入逐步进行介绍"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"F7c1q3w5GJD2","outputId":"6c469e3a-65de-4644-fa37-ed43de4d72e7"},"outputs":[{"data":{"text/plain":["\u001b[1;31mInit signature:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mDocstring:\u001b[0m     \n","Data loader. Combines a dataset and a sampler, and provides an iterable over\n","the given dataset.\n","\n","The :class:`~torch.utils.data.DataLoader` supports both map-style and\n","iterable-style datasets with single- or multi-process loading, customizing\n","loading order and optional automatic batching (collation) and memory pinning.\n","\n","See :py:mod:`torch.utils.data` documentation page for more details.\n","\n","Arguments:\n","    dataset (Dataset): dataset from which to load the data.\n","    batch_size (int, optional): how many samples per batch to load\n","        (default: ``1``).\n","    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n","        at every epoch (default: ``False``).\n","    sampler (Sampler or Iterable, optional): defines the strategy to draw\n","        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n","        implemented. If specified, :attr:`shuffle` must not be specified.\n","    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n","        returns a batch of indices at a time. Mutually exclusive with\n","        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n","        and :attr:`drop_last`.\n","    num_workers (int, optional): how many subprocesses to use for data\n","        loading. ``0`` means that the data will be loaded in the main process.\n","        (default: ``0``)\n","    collate_fn (callable, optional): merges a list of samples to form a\n","        mini-batch of Tensor(s).  Used when using batched loading from a\n","        map-style dataset.\n","    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n","        into CUDA pinned memory before returning them.  If your data elements\n","        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n","        see the example below.\n","    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n","        if the dataset size is not divisible by the batch size. If ``False`` and\n","        the size of dataset is not divisible by the batch size, then the last batch\n","        will be smaller. (default: ``False``)\n","    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n","        from workers. Should always be non-negative. (default: ``0``)\n","    worker_init_fn (callable, optional): If not ``None``, this will be called on each\n","        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n","        input, after seeding and before data loading. (default: ``None``)\n","    prefetch_factor (int, optional, keyword-only arg): Number of sample loaded\n","        in advance by each worker. ``2`` means there will be a total of\n","        2 * num_workers samples prefetched across all workers. (default: ``2``)\n","    persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n","        the worker processes after a dataset has been consumed once. This allows to \n","        maintain the workers `Dataset` instances alive. (default: ``False``)\n","\n","\n",".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n","             cannot be an unpicklable object, e.g., a lambda function. See\n","             :ref:`multiprocessing-best-practices` on more details related\n","             to multiprocessing in PyTorch.\n","\n",".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n","             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n","             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n","             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n","             configurations. This represents the best guess PyTorch can make because PyTorch\n","             trusts user :attr:`dataset` code in correctly handling multi-process\n","             loading to avoid duplicate data.\n","\n","             However, if sharding results in multiple workers having incomplete last batches,\n","             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n","             be broken into multiple ones and (2) more than one batch worth of samples can be\n","             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n","             cases in general.\n","\n","             See `Dataset Types`_ for more details on these two types of datasets and how\n","             :class:`~torch.utils.data.IterableDataset` interacts with\n","             `Multi-process data loading`_.\n","\u001b[1;31mFile:\u001b[0m           d:\\users\\asus\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\n","\u001b[1;31mType:\u001b[0m           type\n","\u001b[1;31mSubclasses:\u001b[0m     \n"]},"metadata":{},"output_type":"display_data"}],"source":["DataLoader?"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"LKUsLmPtGJD2","executionInfo":{"status":"ok","timestamp":1651862260016,"user_tz":-120,"elapsed":222,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["train_loader = DataLoader(LBC_train, batch_size=10, shuffle=True)"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"zipElMCeGJD3","executionInfo":{"status":"ok","timestamp":1651862261217,"user_tz":-120,"elapsed":232,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["test_loader = DataLoader(LBC_test, batch_size=10, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"53IF9TfQGJD3"},"source":["> 此处需要注意，对于测试集来说，数据装载并不是一定要进行的，如果测试集只是用于检测模型效果，有时可以不用装载直接带入计算。"]},{"cell_type":"markdown","metadata":{"id":"rKMAoa9WGJD4"},"source":["同样，经过DataLoader处理后的数据也可以使用dataset属性查看原数据"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mgL4XYWLGJD4","executionInfo":{"status":"ok","timestamp":1651862311177,"user_tz":-120,"elapsed":231,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"67b48dea-ab94-4eb0-b207-19a8f1a370f1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.utils.data.dataset.Subset at 0x7f0226c4a250>"]},"metadata":{},"execution_count":46}],"source":["train_loader.dataset"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aMQ_BXwzGJD5","executionInfo":{"status":"ok","timestamp":1651862314394,"user_tz":-120,"elapsed":199,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"b6bf3b21-2b5a-462b-f01d-5259183f90d5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.utils.data.dataset.Subset at 0x7f0226c4a250>"]},"metadata":{},"execution_count":47}],"source":["LBC_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WqacWSFDGJD5","outputId":"cbdff0be-4bd4-47cb-a188-c39e0a2cdbe7"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["train_loader.dataset == LBC_train"]},{"cell_type":"markdown","metadata":{"id":"yWWQpn2_GJD6"},"source":["> 这里值得一提的是，市面上有很多教材在介绍PyTorch深度学习建模过程中的数据集划分过程，会推荐使用scikit-learn中的train_test_split函数。该函数是可以非常便捷的完成数据集切分，但这种做法只能用于单机运行的数据，并且切分之后还要调用Dataset、DataLoader模块进行数据封装和加载，切分过程看似简单，但其实会额外占用非常多的存储空间和计算资源，当进行超大规模数据训练时，所造成的影响会非常明显（当然，也有可能由于数据规模过大，本地无法运行）。因此，为了更好的适应深度学习真实应用场景，在使用包括数据切分等常用函数时，函数使用优先级是      \n","<center>Pytorch原生函数和类>依据张量及其常用方法手动创建的函数>Scikit-Learn函数"]},{"cell_type":"markdown","metadata":{"id":"B7MEDCw0GJD7"},"source":["### 2.建模及评估过程"]},{"cell_type":"markdown","metadata":{"id":"uJjNyPczGJD8"},"source":["&emsp;&emsp;接下来，我们尝试通过调库实现完整的数据切分、训练、查看建模结果一整个流程。"]},{"cell_type":"markdown","metadata":{"id":"3PyhO6G3GJD9"},"source":["- 数据准备过程"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"fbR9gvSLGJD9","executionInfo":{"status":"ok","timestamp":1651862667587,"user_tz":-120,"elapsed":223,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["# 生成数据\n","features, labels = tensorGenReg()\n","features = features[:, :-1]                                  # 剔除最后全是1的列\n","\n","# 创建一个针对手动创建数据的数据类\n","class GenData(Dataset):\n","    def __init__(self, features, labels):           # 创建该类时需要输入的数据集\n","        self.features = features                    # features属性返回数据集特征\n","        self.labels = labels                        # labels属性返回数据集标签\n","        self.lens = len(features)                   # lens属性返回数据集大小\n","\n","    def __getitem__(self, index):\n","        # 调用该方法时需要输入index数值，方法最终返回index对应的特征和标签\n","        return self.features[index,:],self.labels[index]    \n","\n","    def __len__(self):\n","        # 调用该方法不需要输入额外参数，方法最终返回数据集大小\n","        return self.lens\n","\n","# 实例化对象\n","data = GenData(features, labels)\n","    \n","# 切分数据集\n","num_train = int(data.lens * 0.7)\n","num_test = data.lens - num_train\n","data_train, data_test = random_split(data, [num_train, num_test])\n","\n","# 加载数据\n","train_loader = DataLoader(data_train, batch_size=10, shuffle=True)\n","test_loader = DataLoader(data_test, batch_size=10, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"W6J2Lln0GJD-"},"source":["- 构建模型"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"FD-A6Nc3GJD-","executionInfo":{"status":"ok","timestamp":1651862718534,"user_tz":-120,"elapsed":220,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["# 初始化核心参数\n","batch_size = 10                                # 小批的数量\n","lr = 0.03                                      # 学习率\n","num_epochs = 3                                 # 训练过程遍历几次数据\n","\n","# Stage 1.定义模型\n","class LR(nn.Module):\n","    def __init__(self, in_features=2, out_features=1):       # 定义模型的点线结构\n","        super(LR, self).__init__()\n","        self.linear = nn.Linear(in_features, out_features)\n","        \n","    def forward(self, x):                                    # 定义模型的正向传播规则\n","        out = self.linear(x)             \n","        return out\n","\n","# 实例化模型\n","LR_model = LR()\n","\n","# Stage 2.定义损失函数\n","criterion = nn.MSELoss()\n","\n","# Stage 3.定义优化方法\n","optimizer = optim.SGD(LR_model.parameters(), lr = 0.03)\n","\n","# Stage 4.模型训练与测试\n","def fit(net, criterion, optimizer, batchdata, epochs=3):\n","    for epoch  in range(epochs):\n","        for X, y in batchdata:\n","            yhat = net.forward(X)\n","            loss = criterion(yhat, y)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()"]},{"cell_type":"markdown","metadata":{"id":"-sm57awCGJD-"},"source":["- 模型训练与测试"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"Ea9UzUg2GJD-","executionInfo":{"status":"ok","timestamp":1651862734491,"user_tz":-120,"elapsed":245,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["fit(net = LR_model,\n","    criterion = criterion,\n","    optimizer = optimizer,\n","    batchdata = train_loader,\n","    epochs = num_epochs\n",")"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kiic7ruwGJD_","executionInfo":{"status":"ok","timestamp":1651862736243,"user_tz":-120,"elapsed":209,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"ec357ce3-55f1-4f98-ad27-126259218fcd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LR(\n","  (linear): Linear(in_features=2, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":51}],"source":["# 查看训练模型\n","LR_model"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1nV51WOhGJD_","executionInfo":{"status":"ok","timestamp":1651862737851,"user_tz":-120,"elapsed":207,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"5f8d1869-39c2-4b98-e5a9-f4f50274a69d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Parameter containing:\n"," tensor([[ 1.9997, -0.9998]], requires_grad=True), Parameter containing:\n"," tensor([1.0001], requires_grad=True)]"]},"metadata":{},"execution_count":52}],"source":["# 查看模型参数\n","list(LR_model.parameters())"]},{"cell_type":"markdown","metadata":{"id":"dGnFsk2zGJD_"},"source":["查看模型在训练集上表现，首先我们可以通过dataset和indices方法还原训练数据集"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"Ypp7sZusGJD_"},"outputs":[],"source":["data_train.indices            # 返回训练集索引"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"id":"_hvJejlpGJD_"},"outputs":[],"source":["data[data_train.indices]      # 返回训练集"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rIK9-zlqGJEA","executionInfo":{"status":"ok","timestamp":1651862801400,"user_tz":-120,"elapsed":217,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"4f16270a-fc08-4e60-df9d-70b9b20b1c43"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.6472, -0.2646],\n","        [ 0.3770,  1.5112],\n","        [-0.7582, -0.1615],\n","        ...,\n","        [-0.2332,  0.0937],\n","        [ 2.1642, -0.9784],\n","        [-0.7842,  1.2941]])"]},"metadata":{},"execution_count":57}],"source":["data[data_train.indices][0]      # 返回训练集的特征"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"THdJAR0zGJEA","executionInfo":{"status":"ok","timestamp":1651862749001,"user_tz":-120,"elapsed":207,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"105d88c0-83c7-4e75-a127-8558d7442827"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.0001, grad_fn=<MseLossBackward0>)"]},"metadata":{},"execution_count":53}],"source":["# 计算训练集MSE\n","F.mse_loss(LR_model(data[data_train.indices][0]), data[data_train.indices][1])"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f2kpsJDpGJEA","executionInfo":{"status":"ok","timestamp":1651862818912,"user_tz":-120,"elapsed":231,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"f5e07538-d24a-4734-fcb1-234df48a7b9b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(9.6973e-05, grad_fn=<MseLossBackward0>)"]},"metadata":{},"execution_count":58}],"source":["# 计算测试集MSE\n","F.mse_loss(LR_model(data[data_test.indices][0]), data[data_test.indices][1])"]},{"cell_type":"markdown","metadata":{"id":"vt3FNjx5GJEA"},"source":["至此，即完成了整个从数据集切分到模型训练，再到查看模型在不同数据集上表现的全过程。"]},{"cell_type":"markdown","metadata":{"id":"JB09qZ4rGJEB"},"source":["## 五、实用函数补充"]},{"cell_type":"markdown","metadata":{"id":"mCn-f-QLGJEB"},"source":["&emsp;&emsp;结合上述过程，我们可以补充一些实用函数，方便简化后续建模流程。"]},{"cell_type":"markdown","metadata":{"id":"WfYZHLk4GJEB"},"source":["- 数据封装、切分和加载函数"]},{"cell_type":"markdown","metadata":{"id":"6IQvWmLCGJEB"},"source":["&emsp;&emsp;该函数可以直接将输入的特征和标签直接进行封装、切分和加载。该函数可以直接处理此前定义的数据生成器创建的数据。"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"TjrA_4YxGJEB","executionInfo":{"status":"ok","timestamp":1651862940265,"user_tz":-120,"elapsed":217,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["def split_loader(features, labels, batch_size=10, rate=0.7):\n","    \"\"\"数据封装、切分和加载函数：\n","    \n","    :param features：输入的特征 \n","    :param labels: 数据集标签张量\n","    :param batch_size：数据加载时的每一个小批数据量 \n","    :param rate: 训练集数据占比\n","    :return：加载好的训练集和测试集\n","    \"\"\"\n","    data = GenData(features, labels) \n","    num_train = int(data.lens * rate)\n","    num_test = data.lens - num_train\n","    data_train, data_test = random_split(data, [num_train, num_test])\n","    train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n","    test_loader = DataLoader(data_test, batch_size=batch_size, shuffle=False)\n","    return(train_loader, test_loader)"]},{"cell_type":"markdown","metadata":{"id":"Pzd8ny9TGJEC"},"source":["测试函数性能"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-Pn1UxzGJEC","executionInfo":{"status":"ok","timestamp":1651862946329,"user_tz":-120,"elapsed":222,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"e24f6956-aaa8-44b5-f4cc-0a4fde06b613"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f023ee04050>"]},"metadata":{},"execution_count":61}],"source":["# 设置随机数种子\n","torch.manual_seed(420)   \n","\n","# 创建数据集\n","features, labels = tensorGenReg()\n","features = features[:, :-1]  \n","\n","# 进行数据加载\n","train_loader, test_loader = split_loader(features, labels)"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hbSr3wlSGJEC","executionInfo":{"status":"ok","timestamp":1651862948685,"user_tz":-120,"elapsed":216,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"5079874a-1692-472a-b4ac-bd2250c7957d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([-1.4463, -0.6221]), tensor([-1.2863]))"]},"metadata":{},"execution_count":62}],"source":["# 查看第一条训练集数据\n","train_loader.dataset[0]"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oofdE6YdGJEC","executionInfo":{"status":"ok","timestamp":1651862954302,"user_tz":-120,"elapsed":202,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"91fdfd6e-c40b-4d0b-ec58-78a97127ba20"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["700"]},"metadata":{},"execution_count":63}],"source":["len(train_loader.dataset[:][0])"]},{"cell_type":"code","source":["train_loader.dataset[:][0] #特征\n","train_loader.dataset[:][1] #标签"],"metadata":{"id":"E_kxPr2etQIb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hlb-_Uq2GJED"},"source":["- 模型训练函数"]},{"cell_type":"markdown","metadata":{"id":"BjM2cjeYGJED"},"source":["&emsp;&emsp;模型训练函数并不是新的函数，此处正式对其进行定义并写入自定义模块中，方便后续调用。"]},{"cell_type":"code","execution_count":66,"metadata":{"id":"vIPff5d3GJED","executionInfo":{"status":"ok","timestamp":1651863066731,"user_tz":-120,"elapsed":246,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["def fit(net, criterion, optimizer, batchdata, epochs=3, cla=False):\n","    \"\"\"模型训练函数\n","    \n","    :param net：待训练的模型 \n","    :param criterion: 损失函数\n","    :param optimizer：优化算法\n","    :param batchdata: 训练数据集\n","    :param cla: 是否是分类问题\n","    :param epochs: 遍历数据次数\n","    \"\"\"\n","    for epoch  in range(epochs):\n","        for X, y in batchdata:\n","            if cla == True:\n","                y = y.flatten().long()          # 如果是分类问题，需要对y进行整数转化\n","            yhat = net.forward(X)\n","            loss = criterion(yhat, y)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()"]},{"cell_type":"markdown","metadata":{"id":"UgIyE_o0GJED"},"source":["- MSE计算函数"]},{"cell_type":"markdown","metadata":{"id":"l5rYU6e5GJED"},"source":["&emsp;&emsp;接下来，我们借助F.mse_loss，定义一个可以直接根据模型输出结果和加载后的数据计算MSE的函数。"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"LupjIwqgGJED","executionInfo":{"status":"ok","timestamp":1651863090638,"user_tz":-120,"elapsed":222,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["def mse_cal(data_loader, net):\n","    \"\"\"mse计算函数\n","    \n","    :param data_loader：加载好的数据\n","    :param net: 模型\n","    :return：根据输入的数据，输出其MSE计算结果\n","    \"\"\"\n","    data = data_loader.dataset                # 还原Dataset类\n","    X = data[:][0]                            # 还原数据的特征\n","    y = data[:][1]                            # 还原数据的标签\n","    yhat = net(X)\n","    return F.mse_loss(yhat, y)"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tGqYrjM5GJEE","executionInfo":{"status":"ok","timestamp":1651865790658,"user_tz":-120,"elapsed":220,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"3838884a-5f1a-4c03-d5f9-ad320500f98e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-1.4463, -0.6221],\n","        [-0.4742, -0.2939],\n","        [ 1.9870,  0.1949],\n","        ...,\n","        [-1.6366, -2.1399],\n","        [-1.8178, -1.4618],\n","        [ 0.2646,  2.3555]])"]},"metadata":{},"execution_count":68}],"source":["train_loader.dataset[:][0]"]},{"cell_type":"markdown","metadata":{"id":"38B1IstJGJEE"},"source":["接下来，测试函数性能。借助上述建模实验中构建的回归模型，测试函数能否顺利执行。"]},{"cell_type":"code","execution_count":69,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ygieByZLGJEE","executionInfo":{"status":"ok","timestamp":1651865793454,"user_tz":-120,"elapsed":618,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"d31ba3f6-5e43-4fe3-861a-df71493ecb0b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f023ee04050>"]},"metadata":{},"execution_count":69}],"source":["# 设置随机数种子\n","torch.manual_seed(420)   \n","\n","# 实例化模型\n","LR_model = LR()\n","\n","# Stage 2.定义损失函数\n","criterion = nn.MSELoss()\n","\n","# Stage 3.定义优化方法\n","optimizer = optim.SGD(LR_model.parameters(), lr = 0.03)\n","\n","# Stage 4.训练模型\n","fit(net = LR_model,\n","    criterion = criterion,\n","    optimizer = optimizer,\n","    batchdata = train_loader,\n","    epochs = 3\n",")"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N_SERWyQGJEF","executionInfo":{"status":"ok","timestamp":1651865795608,"user_tz":-120,"elapsed":247,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"16a0d10e-2325-40de-84bd-5545e1b7e7af"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["LR(\n","  (linear): Linear(in_features=2, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":70}],"source":["LR_model"]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A4zshCTHGJEF","executionInfo":{"status":"ok","timestamp":1651865797316,"user_tz":-120,"elapsed":221,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"81e5324d-2ea9-4d67-d6e0-433c5e2e9987"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.0001, grad_fn=<MseLossBackward0>)"]},"metadata":{},"execution_count":71}],"source":["mse_cal(train_loader, LR_model)           # 计算训练误差"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADDtjmPnGJEF","executionInfo":{"status":"ok","timestamp":1651865798519,"user_tz":-120,"elapsed":224,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"770fb4ed-d168-45d4-a500-73ce65e0f49a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(8.9603e-05, grad_fn=<MseLossBackward0>)"]},"metadata":{},"execution_count":72}],"source":["mse_cal(test_loader, LR_model)            # 计算测试误差"]},{"cell_type":"markdown","metadata":{"id":"rjL8ImwCGJEF"},"source":["和F.mse_loss对比"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LbAeZBcBGJEF","executionInfo":{"status":"ok","timestamp":1651865801002,"user_tz":-120,"elapsed":224,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"0ddcfc4f-1d7d-41cb-c11a-886125087c0c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.0001, grad_fn=<MseLossBackward0>)"]},"metadata":{},"execution_count":73}],"source":["F.mse_loss(LR_model(train_loader.dataset[:][0]), train_loader.dataset[:][1])"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MkZ8eEL4GJEG","executionInfo":{"status":"ok","timestamp":1651865803004,"user_tz":-120,"elapsed":203,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"7d242d5f-f5f8-457d-d984-9b5bb7486a47"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(8.9603e-05, grad_fn=<MseLossBackward0>)"]},"metadata":{},"execution_count":74}],"source":["F.mse_loss(LR_model(test_loader.dataset[:][0]), test_loader.dataset[:][1])"]},{"cell_type":"markdown","metadata":{"id":"rfW6oFRHGJEG"},"source":["- 准确率计算函数"]},{"cell_type":"markdown","metadata":{"id":"qzkZW6xfGJEG"},"source":["&emsp;&emsp;类似的，定义一个分类问题的准确率计算函数，同样要求输入是加载后的数据集和训练完成的模型。"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"qKvg5YrlGJEG","executionInfo":{"status":"ok","timestamp":1651865812272,"user_tz":-120,"elapsed":201,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["def accuracy_cal(data_loader, net):\n","    \"\"\"准确率\n","    \n","    :param data_loader：加载好的数据\n","    :param net: 模型\n","    :return：根据输入的数据，输出其准确率计算结果\n","    \"\"\"\n","    data = data_loader.dataset                # 还原Dataset类\n","    X = data[:][0]                            # 还原数据的特征\n","    y = data[:][1]                            # 还原数据的标签\n","    zhat = net(X)                             # 默认是分类问题，并且输出结果是未经softmax转化的结果\n","    soft_z = F.softmax(zhat, 1)                  # 进行softmax转化\n","    acc_bool = torch.argmax(soft_z, 1).flatten() == y.flatten()\n","    acc = torch.mean(acc_bool.float())\n","    return acc         "]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D8PRVfXmGJEH","executionInfo":{"status":"ok","timestamp":1651865925627,"user_tz":-120,"elapsed":351,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"c5774bb1-68b7-4497-b17b-ad72f88cfe5a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 1., 2.],\n","        [3., 4., 5.],\n","        [6., 7., 8.]])"]},"metadata":{},"execution_count":76}],"source":["t = torch.arange(9).reshape(3, 3).float()\n","t"]},{"cell_type":"code","execution_count":77,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05b6eW-OGJEH","executionInfo":{"status":"ok","timestamp":1651865927057,"user_tz":-120,"elapsed":246,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"1c4f3bb8-d363-4d10-d049-83e96c483081"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0900, 0.2447, 0.6652],\n","        [0.0900, 0.2447, 0.6652],\n","        [0.0900, 0.2447, 0.6652]])"]},"metadata":{},"execution_count":77}],"source":["F.softmax(t, 1)"]},{"cell_type":"markdown","metadata":{"id":"cR2__0JRGJEH"},"source":["接下来，测试函数性能："]},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W5fxifNuGJEH","executionInfo":{"status":"ok","timestamp":1651865933005,"user_tz":-120,"elapsed":497,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"710d1b3c-e3c5-4ef0-cc6c-80f699f976cc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f023ee04050>"]},"metadata":{},"execution_count":78}],"source":["# 设置随机数种子\n","torch.manual_seed(420)   \n","\n","# 创建分类数据集\n","features, labels = tensorGenCla()\n","\n","# 进行数据加载\n","train_loader, test_loader = split_loader(features, labels)"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"GYvNy3kiGJEH","executionInfo":{"status":"ok","timestamp":1651865942486,"user_tz":-120,"elapsed":495,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}}},"outputs":[],"source":["class softmaxR(nn.Module):\n","    def __init__(self, in_features=2, out_features=3, bias=False):      # 定义模型的点线结构\n","        super(softmaxR, self).__init__()\n","        self.linear = nn.Linear(in_features, out_features)\n","        \n","    def forward(self, x):                            # 定义模型的正向传播规则\n","        out = self.linear(x)             \n","        return out\n","\n","# 实例化模型和\n","softmax_model = softmaxR()\n","\n","# 定义损失函数\n","criterion = nn.CrossEntropyLoss()\n","\n","# 定义优化算法\n","optimizer = optim.SGD(softmax_model.parameters(), lr = lr)\n","\n","# 执行模型训练\n","fit(net = softmax_model, \n","    criterion = criterion, \n","    optimizer = optimizer, \n","    batchdata = train_loader, \n","    epochs = num_epochs, \n","    cla=True)"]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0JwdpTILGJEI","executionInfo":{"status":"ok","timestamp":1651866000883,"user_tz":-120,"elapsed":220,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"ca24913e-4d92-40de-893e-9239b0ad8dd4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.8438)"]},"metadata":{},"execution_count":80}],"source":["accuracy_cal(train_loader, softmax_model)"]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4LjG9SKWGJEI","executionInfo":{"status":"ok","timestamp":1651866002861,"user_tz":-120,"elapsed":224,"user":{"displayName":"李镜璇","userId":"01439314030893178341"}},"outputId":"53b911ba-4a5f-4283-c0b3-b6bc1edaef68"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.8444)"]},"metadata":{},"execution_count":81}],"source":["accuracy_cal(test_loader, softmax_model)"]},{"cell_type":"markdown","metadata":{"id":"uX_w2enhGJEI"},"source":["至此，完成本阶段实用函数的添加。"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"Lesson 13.1 深度学习建模目标与性能评估理论.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}