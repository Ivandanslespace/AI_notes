{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5e8fd3d1b378>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m#与可以重复进行的正向传播不同，一次正向传播后，反向传播只能进行一次\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m#如果希望能够重复进行反向传播，可以在进行第一次反向传播的时候加上参数retain_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "#导入库、数据、定义神经网络类，完成正向传播\n",
    "\n",
    "#继承nn.Module类完成正向传播\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#确定数据\n",
    "torch.manual_seed(420)\n",
    "X = torch.rand((500,20),dtype=torch.float32) * 100\n",
    "y = torch.randint(low=0,high=3,size=(500,),dtype=torch.float32)\n",
    "\n",
    "#定义神经网路的架构\n",
    "\"\"\"\n",
    "注意：这是一个三分类的神经网络，因此我们需要调用的损失函数多分类交叉熵函数CEL\n",
    "CEL类已经内置了softmax功能，因此我们需要修改一下网络架构，删除forward函数中输出层上的softmax函数，并将最终的输出修改为zhat\n",
    "\"\"\"\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,in_features=10,out_features=2):\n",
    "        super(Model,self).__init__() #super(请查找这个类的父类，请使用找到的父类替换现在的类)\n",
    "        self.linear1 = nn.Linear(in_features,13,bias=True) #输入层不用写，这里是隐藏层的第一层\n",
    "        self.linear2 = nn.Linear(13,8,bias=True)\n",
    "        self.output = nn.Linear(8,out_features,bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        sigma1 = torch.relu(self.linear1(x))\n",
    "        sigma2 = torch.sigmoid(self.linear2(sigma1))\n",
    "        zhat = self.output(sigma2)\n",
    "        return zhat\n",
    "\n",
    "input_ = X.shape[1] #特征的数目\n",
    "output_ = len(y.unique()) #分类的数目\n",
    "\n",
    "#实例化神经网络类\n",
    "torch.manual_seed(420)\n",
    "net = Model(in_features=input_, out_features=output_)\n",
    "\n",
    "#前向传播\n",
    "zhat = net.forward(X)\n",
    "\n",
    "#定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#对打包好的CorssEnrtopyLoss而言，只需要输入zhat\n",
    "loss = criterion(zhat,y.long())\n",
    "\n",
    "loss\n",
    "\n",
    "net.linear1.weight.grad #不会返回任何值\n",
    "\n",
    "#反向传播，backward是任意损失函数类都可以调用的方法，对任意损失函数，backward都会求解其中全部w的梯度\n",
    "loss.backward()\n",
    "\n",
    "net.linear1.weight.grad #返回相应的梯度\n",
    "\n",
    "#与可以重复进行的正向传播不同，一次正向传播后，反向传播只能进行一次\n",
    "#如果希望能够重复进行反向传播，可以在进行第一次反向传播的时候加上参数retain_graph\n",
    "loss.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-825f1f2a4c83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;31m#与可以重复进行的正向传播不同，一次正向传播后，反向传播只能进行一次\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;31m#如果希望能够重复进行反向传播，可以在进行第一次反向传播的时候加上参数retain_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (linear1): Linear(in_features=20, out_features=13, bias=True)\n",
       "  (linear2): Linear(in_features=13, out_features=8, bias=True)\n",
       "  (output): Linear(in_features=8, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net #正向传播、反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.3726e-04,  8.3354e-05,  4.0867e-04,  4.3058e-05,  1.4551e-04,\n",
       "          6.5092e-05,  3.7088e-04,  2.8794e-04,  1.0495e-04,  4.7446e-05,\n",
       "          8.8153e-05,  1.6899e-04,  1.0251e-04,  3.6197e-04,  1.2129e-04,\n",
       "          7.2405e-05,  1.4479e-04,  4.9114e-06,  1.0770e-04,  9.5156e-05],\n",
       "        [ 8.2042e-03,  2.1974e-02,  2.1073e-02,  1.3896e-02,  2.2161e-02,\n",
       "          1.5936e-02,  1.6537e-02,  2.0259e-02,  1.9655e-02,  1.4728e-02,\n",
       "          1.9212e-02,  2.0087e-02,  1.8295e-02,  8.4133e-03,  1.8036e-02,\n",
       "          1.9979e-02,  2.0966e-02,  2.4730e-02,  9.3876e-03,  1.7475e-02],\n",
       "        [ 9.1603e-03,  2.4275e-02,  2.3446e-02,  2.0096e-02,  2.5360e-02,\n",
       "          1.7406e-02,  3.2556e-02,  2.2461e-02,  3.6794e-03,  2.7445e-02,\n",
       "          2.1181e-02,  2.7724e-02,  1.7115e-02,  1.6943e-02,  1.7249e-02,\n",
       "          3.3174e-02,  1.5115e-02,  3.0874e-02,  1.8391e-02,  2.4201e-02],\n",
       "        [-2.8594e-04,  1.2968e-03,  1.3652e-03, -5.6689e-05, -1.7480e-03,\n",
       "         -2.6459e-03,  3.7307e-04, -2.7976e-03,  1.7848e-03, -9.9289e-04,\n",
       "         -3.3944e-04,  2.2783e-04,  1.2076e-03, -3.2906e-04,  5.4641e-04,\n",
       "         -2.8959e-03, -2.7890e-03, -3.0774e-03, -3.8981e-03, -6.0863e-03],\n",
       "        [ 1.5692e-03,  1.3161e-03, -9.0901e-04, -1.0158e-03, -4.9426e-03,\n",
       "          1.3061e-03, -6.8428e-03, -1.0955e-02,  4.2489e-03, -9.7841e-03,\n",
       "         -3.5232e-03, -6.9716e-03,  1.0742e-02,  2.9732e-03, -2.2283e-03,\n",
       "         -4.3101e-03, -1.2823e-03, -6.0040e-03, -1.5857e-03, -3.2208e-03],\n",
       "        [-2.3456e-03,  3.0269e-04, -9.7571e-04, -1.7812e-03, -1.9554e-03,\n",
       "          4.7728e-04, -7.5906e-04, -9.3554e-04, -8.6828e-04, -4.9501e-04,\n",
       "         -3.2291e-03, -2.6119e-03, -9.4872e-04, -1.3638e-03, -1.7115e-03,\n",
       "         -9.1220e-04, -1.0843e-03, -8.5493e-04,  1.5598e-04, -2.5193e-03],\n",
       "        [-1.8459e-02, -2.0009e-02, -1.3430e-02, -1.5675e-02, -1.3660e-02,\n",
       "         -1.4804e-02, -8.0083e-03, -2.0027e-02, -2.9173e-02,  7.5748e-03,\n",
       "         -1.8572e-02, -5.4350e-03, -3.2866e-02, -9.2504e-03, -1.8047e-02,\n",
       "         -9.1732e-03, -1.6036e-02, -1.4584e-02, -8.9602e-03,  1.7229e-03],\n",
       "        [ 9.5592e-04, -2.0620e-02, -2.6421e-02, -1.9139e-02, -2.5206e-02,\n",
       "         -9.0115e-03, -2.5945e-02, -1.8858e-02, -3.5860e-03, -3.2187e-02,\n",
       "         -1.8400e-02, -1.8522e-02, -1.1765e-02, -1.5216e-02, -8.4283e-03,\n",
       "         -3.0337e-02, -1.1364e-02, -2.9159e-02, -5.1049e-03, -2.6377e-02],\n",
       "        [ 3.7390e-03, -1.3553e-03, -2.2382e-03,  2.2693e-03, -1.4464e-03,\n",
       "         -2.4332e-03, -3.7882e-03,  7.3998e-04,  1.2527e-02, -1.9007e-03,\n",
       "          7.8561e-03, -9.5000e-03,  9.1147e-03, -2.2882e-03,  5.5781e-03,\n",
       "         -5.0263e-03,  4.8214e-03,  2.0531e-03,  4.1112e-04, -2.4565e-03],\n",
       "        [ 2.4338e-03,  2.9046e-03, -1.0326e-02, -4.4876e-03, -8.1676e-05,\n",
       "         -3.0232e-03,  3.2874e-03, -7.5255e-03, -1.0000e-02,  3.9967e-03,\n",
       "          6.3736e-03, -2.3521e-03, -3.5956e-03, -4.8027e-03, -2.7523e-03,\n",
       "          1.6497e-03, -1.3330e-03,  3.1406e-03,  4.9480e-03, -1.5097e-03],\n",
       "        [-7.3584e-04,  9.5657e-04,  1.6132e-03,  2.9669e-03, -1.5606e-03,\n",
       "          2.1566e-03, -5.9969e-04,  1.0974e-03,  2.8536e-03, -1.5761e-03,\n",
       "         -1.1973e-03,  1.4157e-03,  1.0819e-03, -1.6395e-04,  1.4259e-03,\n",
       "         -1.5992e-03,  4.9925e-04,  2.4320e-03,  2.8718e-03,  7.4142e-04],\n",
       "        [-1.3084e-02, -1.9413e-02, -3.0946e-02, -2.5855e-02, -2.5361e-02,\n",
       "         -1.3386e-02, -1.6360e-02, -1.5787e-02, -2.4764e-02, -2.0017e-02,\n",
       "         -1.5216e-02, -1.7700e-02, -1.4559e-02, -2.9177e-02, -1.7573e-02,\n",
       "         -1.8530e-02, -1.0069e-02, -9.5260e-03, -1.8987e-02, -1.7839e-02],\n",
       "        [ 4.8107e-04,  7.2480e-04,  9.8633e-05,  8.6471e-04,  1.9964e-03,\n",
       "          1.6202e-03,  1.1736e-03,  2.0290e-03,  3.3147e-04,  3.0171e-03,\n",
       "          1.0456e-03,  1.1400e-03,  5.0297e-04,  3.3159e-04,  1.9707e-03,\n",
       "          3.4884e-04,  8.4107e-04,  2.6777e-03,  8.6282e-04,  5.8412e-04]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w(t+1) = w(t) - 步长 * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 10 #learning_rate, 0.001,0.01,0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3656e-01, -1.3459e-01,  2.1281e-01, -1.7763e-01, -6.8218e-02,\n",
       "         -1.5410e-01,  1.7245e-01,  8.3885e-02, -1.1153e-01, -1.7294e-01,\n",
       "         -1.2947e-01, -4.3138e-02, -1.1413e-01,  1.6295e-01, -9.4082e-02,\n",
       "         -1.4629e-01, -6.8982e-02, -2.1836e-01, -1.0859e-01, -1.2199e-01],\n",
       "        [ 4.8127e-02,  1.8186e-01,  2.4149e-02, -1.3032e-01,  9.2056e-02,\n",
       "         -9.5202e-02, -1.0584e-01, -4.2852e-02, -1.1669e-01,  2.4581e-02,\n",
       "          1.8152e-01,  3.0500e-02,  1.3506e-01, -1.9425e-01, -1.7591e-01,\n",
       "         -2.9751e-02,  2.0485e-04,  1.3957e-01, -1.9666e-01,  9.3293e-02],\n",
       "        [-1.9192e-01,  3.6070e-02,  1.4778e-01,  3.0845e-02,  7.1393e-02,\n",
       "          1.4217e-01,  2.2122e-01, -1.4032e-01,  7.3255e-02,  1.8409e-01,\n",
       "          1.2716e-01, -2.0253e-01, -1.5509e-01, -2.1899e-01,  9.8980e-02,\n",
       "          2.2123e-01, -2.1659e-01,  1.7880e-01, -2.0922e-01, -2.7275e-02],\n",
       "        [ 1.8144e-01, -3.5166e-02,  2.4801e-02,  1.6299e-01, -1.8755e-01,\n",
       "          5.6587e-02, -1.0911e-01,  2.0523e-01, -1.9378e-01,  1.6899e-02,\n",
       "          1.3966e-01, -1.3137e-01, -1.3201e-01,  7.6554e-02, -1.7558e-01,\n",
       "          1.3096e-01,  2.7182e-02, -2.2010e-01,  7.6883e-02, -1.8731e-01],\n",
       "        [ 2.7419e-02,  1.3699e-01, -3.8687e-02,  8.3463e-02, -1.5634e-02,\n",
       "         -1.6781e-01, -2.1426e-01,  1.8463e-01,  8.3891e-02,  5.9950e-02,\n",
       "         -2.0538e-01, -2.7832e-02,  4.7442e-02, -1.9782e-01, -1.7842e-01,\n",
       "          1.1362e-01,  1.4101e-01, -1.3794e-01,  1.1704e-01, -3.4108e-02],\n",
       "        [ 3.8388e-02, -1.7268e-01, -1.0235e-01, -1.2634e-01, -1.1883e-01,\n",
       "         -1.3463e-01, -1.7610e-01,  3.6543e-02, -1.7834e-01, -1.6471e-01,\n",
       "          2.0834e-01,  1.8400e-01, -8.8723e-02, -7.5378e-02,  1.7877e-01,\n",
       "         -5.7259e-02, -2.4522e-02, -1.1822e-02, -1.8196e-01,  1.9812e-01],\n",
       "        [-2.2011e-02,  2.1847e-01,  1.8410e-01,  9.7177e-02, -5.0634e-03,\n",
       "         -2.4731e-03,  5.1408e-03, -2.1733e-01, -5.3375e-02, -1.0346e-01,\n",
       "         -1.3303e-02,  2.7354e-02, -1.7523e-01,  1.6994e-01,  1.8259e-01,\n",
       "          1.3907e-01,  1.0041e-01,  3.5377e-02, -1.6114e-01,  9.0056e-02],\n",
       "        [ 7.9232e-02,  2.1614e-01, -2.1087e-01,  1.9407e-01,  1.7559e-01,\n",
       "          4.1470e-02,  7.4482e-02,  2.6737e-02, -1.7872e-02,  4.5040e-02,\n",
       "          1.2947e-01,  2.5483e-02, -2.0320e-02, -7.3942e-03, -1.7221e-01,\n",
       "         -1.0705e-01,  1.8203e-01,  1.3179e-02,  2.3468e-02, -1.9567e-01],\n",
       "        [ 1.6338e-01,  8.0209e-03, -2.9885e-02, -2.1884e-01,  1.3471e-01,\n",
       "         -2.8901e-02, -1.8757e-01,  8.9256e-03,  2.0940e-01,  9.0927e-02,\n",
       "         -8.2969e-02, -9.0893e-03,  1.0047e-01, -1.6897e-02, -1.3736e-01,\n",
       "          1.6801e-01, -1.9342e-01, -3.4822e-02,  1.0057e-01,  2.2273e-02],\n",
       "        [ 1.4611e-01,  1.4414e-01, -2.3093e-02,  8.1946e-02,  5.9792e-03,\n",
       "          6.7672e-02,  1.5254e-01,  1.6742e-01, -1.6896e-01,  1.1571e-01,\n",
       "         -1.8538e-01,  2.3316e-02, -1.6147e-01,  1.0230e-01, -1.7314e-01,\n",
       "         -1.8906e-01, -2.0286e-01, -2.1210e-02, -2.1799e-02, -3.7921e-02],\n",
       "        [ 1.9375e-01,  5.3921e-02, -1.4900e-01,  1.6709e-01, -1.6652e-01,\n",
       "          6.2363e-02, -4.1574e-02, -2.0565e-01, -1.3649e-01, -2.0600e-01,\n",
       "         -1.9032e-01, -8.8942e-02, -7.8061e-02,  1.6323e-01, -1.3174e-01,\n",
       "          5.8638e-02,  2.1117e-01,  1.6707e-01, -5.9492e-02, -2.0973e-01],\n",
       "        [-2.5644e-02, -1.0818e-02, -3.3051e-02,  3.7071e-02, -1.0809e-01,\n",
       "          2.0642e-01,  1.2396e-01, -2.1523e-01,  1.2172e-01, -1.4323e-01,\n",
       "          1.1334e-01,  4.6931e-02,  8.4553e-02,  2.0530e-01, -1.1833e-01,\n",
       "          1.9287e-01, -2.8398e-02,  7.1443e-03, -2.1055e-01,  1.0805e-01],\n",
       "        [-1.2258e-01, -6.8325e-02, -2.1929e-01, -1.4939e-01,  1.9226e-01,\n",
       "         -6.2922e-02, -7.6377e-02,  2.1955e-01, -4.5838e-02,  9.8011e-03,\n",
       "         -2.9400e-03, -9.5241e-02, -7.9775e-02, -1.8708e-01,  1.7828e-01,\n",
       "         -1.7552e-01, -1.0328e-01, -1.9697e-02, -1.7449e-01,  2.0408e-02]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = net.linear1.weight.data #现有的权重，w(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = net.linear1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w = w - lr * dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "w -= lr*dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0954e-01, -1.4127e-01,  1.8007e-01, -1.8107e-01, -7.9873e-02,\n",
       "         -1.5931e-01,  1.4275e-01,  6.0821e-02, -1.1993e-01, -1.7674e-01,\n",
       "         -1.3653e-01, -5.6674e-02, -1.2234e-01,  1.3395e-01, -1.0380e-01,\n",
       "         -1.5209e-01, -8.0580e-02, -2.1876e-01, -1.1722e-01, -1.2961e-01],\n",
       "        [-6.0903e-01, -1.5783e+00, -1.6638e+00, -1.2434e+00, -1.6831e+00,\n",
       "         -1.3717e+00, -1.4305e+00, -1.6656e+00, -1.6911e+00, -1.1551e+00,\n",
       "         -1.3574e+00, -1.5784e+00, -1.3303e+00, -8.6816e-01, -1.6206e+00,\n",
       "         -1.6301e+00, -1.6791e+00, -1.8413e+00, -9.4861e-01, -1.3064e+00],\n",
       "        [-9.2566e-01, -1.9084e+00, -1.7302e+00, -1.5788e+00, -1.9599e+00,\n",
       "         -1.2521e+00, -2.3865e+00, -1.9395e+00, -2.2146e-01, -2.0142e+00,\n",
       "         -1.5694e+00, -2.4232e+00, -1.5260e+00, -1.5762e+00, -1.2827e+00,\n",
       "         -2.4360e+00, -1.4273e+00, -2.2942e+00, -1.6824e+00, -1.9658e+00],\n",
       "        [ 2.0435e-01, -1.3904e-01, -8.4551e-02,  1.6753e-01, -4.7541e-02,\n",
       "          2.6853e-01, -1.3899e-01,  4.2932e-01, -3.3675e-01,  9.6429e-02,\n",
       "          1.6685e-01, -1.4962e-01, -2.2874e-01,  1.0291e-01, -2.1935e-01,\n",
       "          3.6292e-01,  2.5058e-01,  2.6395e-02,  3.8912e-01,  3.0020e-01],\n",
       "        [-9.8276e-02,  3.1566e-02,  3.4125e-02,  1.6483e-01,  3.8027e-01,\n",
       "         -2.7243e-01,  3.3385e-01,  1.0621e+00, -2.5645e-01,  8.4365e-01,\n",
       "          7.6826e-02,  5.3059e-01, -8.1300e-01, -4.3597e-01,  6.1672e-05,\n",
       "          4.5887e-01,  2.4372e-01,  3.4298e-01,  2.4406e-01,  2.2388e-01],\n",
       "        [ 2.2627e-01, -1.9693e-01, -2.4200e-02,  1.6330e-02,  3.7789e-02,\n",
       "         -1.7286e-01, -1.1530e-01,  1.1148e-01, -1.0879e-01, -1.2506e-01,\n",
       "          4.6699e-01,  3.9321e-01, -1.2730e-02,  3.3865e-02,  3.1586e-01,\n",
       "          1.5808e-02,  6.2327e-02,  5.6658e-02, -1.9445e-01,  3.9992e-01],\n",
       "        [ 1.4566e+00,  1.8211e+00,  1.2598e+00,  1.3528e+00,  1.0891e+00,\n",
       "          1.1833e+00,  6.4661e-01,  1.3868e+00,  2.2834e+00, -7.1021e-01,\n",
       "          1.4743e+00,  4.6269e-01,  2.4573e+00,  9.1090e-01,  1.6281e+00,\n",
       "          8.7385e-01,  1.3849e+00,  1.2036e+00,  5.5657e-01, -4.7952e-02],\n",
       "        [ 2.6629e-03,  1.8678e+00,  1.9055e+00,  1.7271e+00,  2.1946e+00,\n",
       "          7.6329e-01,  2.1526e+00,  1.5373e+00,  2.6937e-01,  2.6232e+00,\n",
       "          1.6033e+00,  1.5091e+00,  9.2205e-01,  1.2114e+00,  5.0289e-01,\n",
       "          2.3229e+00,  1.0923e+00,  2.3488e+00,  4.3237e-01,  1.9171e+00],\n",
       "        [-1.3612e-01,  1.1658e-01,  1.4940e-01, -4.0061e-01,  2.5058e-01,\n",
       "          1.6600e-01,  1.1586e-01, -5.0347e-02, -7.9401e-01,  2.4318e-01,\n",
       "         -7.1224e-01,  7.5186e-01, -6.2962e-01,  1.6638e-01, -5.8417e-01,\n",
       "          5.7062e-01, -5.7961e-01, -1.9927e-01,  6.7635e-02,  2.1904e-01],\n",
       "        [-4.8838e-02, -8.8521e-02,  8.0403e-01,  4.4141e-01,  1.2521e-02,\n",
       "          3.0983e-01, -1.1078e-01,  7.7021e-01,  6.3206e-01, -2.0443e-01,\n",
       "         -6.9590e-01,  2.1172e-01,  1.2653e-01,  4.8699e-01,  4.7321e-02,\n",
       "         -3.2120e-01, -9.6090e-02, -2.7277e-01, -4.1813e-01,  8.3009e-02],\n",
       "        [ 2.5269e-01, -2.2700e-02, -2.7822e-01, -7.0558e-02, -4.1519e-02,\n",
       "         -1.1038e-01,  6.4611e-03, -2.9355e-01, -3.6506e-01, -7.9755e-02,\n",
       "         -9.4415e-02, -2.0234e-01, -1.6472e-01,  1.7636e-01, -2.4596e-01,\n",
       "          1.8674e-01,  1.7118e-01, -2.7734e-02, -2.8953e-01, -2.6912e-01],\n",
       "        [ 1.0224e+00,  1.5442e+00,  2.4457e+00,  2.1080e+00,  1.9233e+00,\n",
       "          1.2786e+00,  1.4344e+00,  1.0493e+00,  2.1053e+00,  1.4601e+00,\n",
       "          1.3322e+00,  1.4647e+00,  1.2507e+00,  2.5424e+00,  1.2892e+00,\n",
       "          1.6771e+00,  7.7813e-01,  7.7018e-01,  1.3103e+00,  1.5370e+00],\n",
       "        [-1.6111e-01, -1.2638e-01, -2.2719e-01, -2.1866e-01,  3.2347e-02,\n",
       "         -1.9270e-01, -1.7038e-01,  5.7032e-02, -7.2389e-02, -2.3187e-01,\n",
       "         -8.6694e-02, -1.8656e-01, -1.2006e-01, -2.1364e-01,  2.0429e-02,\n",
       "         -2.0346e-01, -1.7065e-01, -2.3418e-01, -2.4360e-01, -2.6380e-02]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v(t) = gamma * v(t-1)  - lr * dw\n",
    "# w(t+1) = w(t) + v(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = net.linear1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = net.linear1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t = 1，走第一步，进行首次迭代的时候，需要一个v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (linear1): Linear(in_features=20, out_features=13, bias=True)\n",
       "  (linear2): Linear(in_features=13, out_features=8, bias=True)\n",
       "  (output): Linear(in_features=8, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 20])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw.shape #500,20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.zeros(dw.shape[0], dw.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v(t) = gamma * v(t-1)  - lr * dw\n",
    "# w(t+1) = w(t) + v(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = gamma * v - lr * dw\n",
    "w += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0815e-01, -1.4162e-01,  1.7838e-01, -1.8125e-01, -8.0475e-02,\n",
       "         -1.5958e-01,  1.4121e-01,  5.9629e-02, -1.2037e-01, -1.7694e-01,\n",
       "         -1.3689e-01, -5.7373e-02, -1.2277e-01,  1.3245e-01, -1.0430e-01,\n",
       "         -1.5239e-01, -8.1179e-02, -2.1878e-01, -1.1767e-01, -1.3001e-01],\n",
       "        [-6.4298e-01, -1.6692e+00, -1.7510e+00, -1.3009e+00, -1.7748e+00,\n",
       "         -1.4376e+00, -1.4989e+00, -1.7494e+00, -1.7724e+00, -1.2161e+00,\n",
       "         -1.4369e+00, -1.6615e+00, -1.4060e+00, -9.0297e-01, -1.6952e+00,\n",
       "         -1.7128e+00, -1.7659e+00, -1.9436e+00, -9.8746e-01, -1.3788e+00],\n",
       "        [-9.6357e-01, -2.0088e+00, -1.8272e+00, -1.6620e+00, -2.0649e+00,\n",
       "         -1.3241e+00, -2.5212e+00, -2.0324e+00, -2.3669e-01, -2.1278e+00,\n",
       "         -1.6571e+00, -2.5379e+00, -1.5968e+00, -1.6463e+00, -1.3541e+00,\n",
       "         -2.5732e+00, -1.4899e+00, -2.4220e+00, -1.7585e+00, -2.0659e+00],\n",
       "        [ 2.0553e-01, -1.4441e-01, -9.0200e-02,  1.6777e-01, -4.0307e-02,\n",
       "          2.7948e-01, -1.4054e-01,  4.4090e-01, -3.4413e-01,  1.0054e-01,\n",
       "          1.6825e-01, -1.5056e-01, -2.3373e-01,  1.0427e-01, -2.2161e-01,\n",
       "          3.7490e-01,  2.6213e-01,  3.9130e-02,  4.0525e-01,  3.2539e-01],\n",
       "        [-1.0477e-01,  2.6120e-02,  3.7886e-02,  1.6903e-01,  4.0072e-01,\n",
       "         -2.7784e-01,  3.6217e-01,  1.1074e+00, -2.7403e-01,  8.8414e-01,\n",
       "          9.1405e-02,  5.5944e-01, -8.5745e-01, -4.4828e-01,  9.2825e-03,\n",
       "          4.7670e-01,  2.4902e-01,  3.6782e-01,  2.5062e-01,  2.3721e-01],\n",
       "        [ 2.3598e-01, -1.9818e-01, -2.0162e-02,  2.3701e-02,  4.5881e-02,\n",
       "         -1.7483e-01, -1.1216e-01,  1.1535e-01, -1.0520e-01, -1.2301e-01,\n",
       "          4.8036e-01,  4.0402e-01, -8.8043e-03,  3.9509e-02,  3.2294e-01,\n",
       "          1.9583e-02,  6.6814e-02,  6.0195e-02, -1.9510e-01,  4.1035e-01],\n",
       "        [ 1.5330e+00,  1.9039e+00,  1.3154e+00,  1.4176e+00,  1.1457e+00,\n",
       "          1.2446e+00,  6.7975e-01,  1.4697e+00,  2.4041e+00, -7.4155e-01,\n",
       "          1.5512e+00,  4.8518e-01,  2.5933e+00,  9.4918e-01,  1.7028e+00,\n",
       "          9.1181e-01,  1.4513e+00,  1.2639e+00,  5.9365e-01, -5.5081e-02],\n",
       "        [-1.2928e-03,  1.9531e+00,  2.0148e+00,  1.8063e+00,  2.2989e+00,\n",
       "          8.0058e-01,  2.2600e+00,  1.6153e+00,  2.8421e-01,  2.7564e+00,\n",
       "          1.6795e+00,  1.5857e+00,  9.7074e-01,  1.2744e+00,  5.3777e-01,\n",
       "          2.4485e+00,  1.1393e+00,  2.4695e+00,  4.5350e-01,  2.0263e+00],\n",
       "        [-1.5159e-01,  1.2219e-01,  1.5866e-01, -4.1000e-01,  2.5656e-01,\n",
       "          1.7607e-01,  1.3154e-01, -5.3409e-02, -8.4585e-01,  2.5104e-01,\n",
       "         -7.4475e-01,  7.9118e-01, -6.6734e-01,  1.7585e-01, -6.0725e-01,\n",
       "          5.9141e-01, -5.9956e-01, -2.0777e-01,  6.5934e-02,  2.2920e-01],\n",
       "        [-5.8909e-02, -1.0054e-01,  8.4676e-01,  4.5998e-01,  1.2859e-02,\n",
       "          3.2234e-01, -1.2438e-01,  8.0135e-01,  6.7344e-01, -2.2097e-01,\n",
       "         -7.2228e-01,  2.2145e-01,  1.4141e-01,  5.0687e-01,  5.8710e-02,\n",
       "         -3.2803e-01, -9.0574e-02, -2.8577e-01, -4.3861e-01,  8.9257e-02],\n",
       "        [ 2.5574e-01, -2.6659e-02, -2.8489e-01, -8.2835e-02, -3.5061e-02,\n",
       "         -1.1931e-01,  8.9427e-03, -2.9809e-01, -3.7687e-01, -7.3233e-02,\n",
       "         -8.9460e-02, -2.0820e-01, -1.6920e-01,  1.7704e-01, -2.5186e-01,\n",
       "          1.9336e-01,  1.6911e-01, -3.7798e-02, -3.0141e-01, -2.7219e-01],\n",
       "        [ 1.0765e+00,  1.6245e+00,  2.5738e+00,  2.2150e+00,  2.0282e+00,\n",
       "          1.3340e+00,  1.5021e+00,  1.1147e+00,  2.2078e+00,  1.5430e+00,\n",
       "          1.3952e+00,  1.5380e+00,  1.3109e+00,  2.6631e+00,  1.3620e+00,\n",
       "          1.7538e+00,  8.1980e-01,  8.0960e-01,  1.3889e+00,  1.6108e+00],\n",
       "        [-1.6310e-01, -1.2938e-01, -2.2760e-01, -2.2224e-01,  2.4086e-02,\n",
       "         -1.9940e-01, -1.7524e-01,  4.8636e-02, -7.3761e-02, -2.4435e-01,\n",
       "         -9.1021e-02, -1.9127e-01, -1.2214e-01, -2.1502e-01,  1.2274e-02,\n",
       "         -2.0490e-01, -1.7413e-01, -2.4526e-01, -2.4717e-01, -2.8797e-02]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##导入库\n",
    "#确定数据、超参数的确定（lr，gamma）\n",
    "#定义伸进网络的架构类Model，类Model需要输入的参数\n",
    "##实例化神经网络的类 - 让神经网络准备好进行正向传播\n",
    "#定义损失函数\n",
    "#定义优化算法\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#确定数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(420)\n",
    "X = torch.rand((500,20),dtype=torch.float32) * 100\n",
    "y = torch.randint(low=0,high=3,size=(500,),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义神经网路的架构\n",
    "\"\"\"\n",
    "注意：这是一个三分类的神经网络，因此我们需要调用的损失函数多分类交叉熵函数CEL\n",
    "CEL类已经内置了softmax功能，因此我们需要修改一下网络架构，删除forward函数中输出层上的softmax函数，并将最终的输出修改为zhat\n",
    "\"\"\"\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,in_features=10,out_features=2):\n",
    "        super(Model,self).__init__() #super(请查找这个类的父类，请使用找到的父类替换现在的类)\n",
    "        self.linear1 = nn.Linear(in_features,13,bias=True) #输入层不用写，这里是隐藏层的第一层\n",
    "        self.linear2 = nn.Linear(13,8,bias=True)\n",
    "        self.output = nn.Linear(8,out_features,bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        sigma1 = torch.relu(self.linear1(x))\n",
    "        sigma2 = torch.sigmoid(self.linear2(sigma1))\n",
    "        zhat = self.output(sigma2)\n",
    "        return zhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = X.shape[1] #特征的数目\n",
    "output_ = len(y.unique()) #分类的数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实例化神经网络类\n",
    "torch.manual_seed(420)\n",
    "net = Model(in_features=input_, out_features=output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.3656e-01, -1.3459e-01,  2.1281e-01, -1.7763e-01, -6.8218e-02,\n",
       "         -1.5410e-01,  1.7245e-01,  8.3885e-02, -1.1153e-01, -1.7294e-01,\n",
       "         -1.2947e-01, -4.3138e-02, -1.1413e-01,  1.6295e-01, -9.4082e-02,\n",
       "         -1.4629e-01, -6.8982e-02, -2.1836e-01, -1.0859e-01, -1.2199e-01],\n",
       "        [ 4.8127e-02,  1.8186e-01,  2.4149e-02, -1.3032e-01,  9.2056e-02,\n",
       "         -9.5202e-02, -1.0584e-01, -4.2852e-02, -1.1669e-01,  2.4581e-02,\n",
       "          1.8152e-01,  3.0500e-02,  1.3506e-01, -1.9425e-01, -1.7591e-01,\n",
       "         -2.9751e-02,  2.0485e-04,  1.3957e-01, -1.9666e-01,  9.3293e-02],\n",
       "        [-1.9192e-01,  3.6070e-02,  1.4778e-01,  3.0845e-02,  7.1393e-02,\n",
       "          1.4217e-01,  2.2122e-01, -1.4032e-01,  7.3255e-02,  1.8409e-01,\n",
       "          1.2716e-01, -2.0253e-01, -1.5509e-01, -2.1899e-01,  9.8980e-02,\n",
       "          2.2123e-01, -2.1659e-01,  1.7880e-01, -2.0922e-01, -2.7275e-02],\n",
       "        [ 1.8144e-01, -3.5166e-02,  2.4801e-02,  1.6299e-01, -1.8755e-01,\n",
       "          5.6587e-02, -1.0911e-01,  2.0523e-01, -1.9378e-01,  1.6899e-02,\n",
       "          1.3966e-01, -1.3137e-01, -1.3201e-01,  7.6554e-02, -1.7558e-01,\n",
       "          1.3096e-01,  2.7182e-02, -2.2010e-01,  7.6883e-02, -1.8731e-01],\n",
       "        [ 2.7419e-02,  1.3699e-01, -3.8687e-02,  8.3463e-02, -1.5634e-02,\n",
       "         -1.6781e-01, -2.1426e-01,  1.8463e-01,  8.3891e-02,  5.9950e-02,\n",
       "         -2.0538e-01, -2.7832e-02,  4.7442e-02, -1.9782e-01, -1.7842e-01,\n",
       "          1.1362e-01,  1.4101e-01, -1.3794e-01,  1.1704e-01, -3.4108e-02],\n",
       "        [ 3.8388e-02, -1.7268e-01, -1.0235e-01, -1.2634e-01, -1.1883e-01,\n",
       "         -1.3463e-01, -1.7610e-01,  3.6543e-02, -1.7834e-01, -1.6471e-01,\n",
       "          2.0834e-01,  1.8400e-01, -8.8723e-02, -7.5378e-02,  1.7877e-01,\n",
       "         -5.7259e-02, -2.4522e-02, -1.1822e-02, -1.8196e-01,  1.9812e-01],\n",
       "        [-2.2011e-02,  2.1847e-01,  1.8410e-01,  9.7177e-02, -5.0634e-03,\n",
       "         -2.4731e-03,  5.1408e-03, -2.1733e-01, -5.3375e-02, -1.0346e-01,\n",
       "         -1.3303e-02,  2.7354e-02, -1.7523e-01,  1.6994e-01,  1.8259e-01,\n",
       "          1.3907e-01,  1.0041e-01,  3.5377e-02, -1.6114e-01,  9.0056e-02],\n",
       "        [ 7.9232e-02,  2.1614e-01, -2.1087e-01,  1.9407e-01,  1.7559e-01,\n",
       "          4.1470e-02,  7.4482e-02,  2.6737e-02, -1.7872e-02,  4.5040e-02,\n",
       "          1.2947e-01,  2.5483e-02, -2.0320e-02, -7.3942e-03, -1.7221e-01,\n",
       "         -1.0705e-01,  1.8203e-01,  1.3179e-02,  2.3468e-02, -1.9567e-01],\n",
       "        [ 1.6338e-01,  8.0209e-03, -2.9885e-02, -2.1884e-01,  1.3471e-01,\n",
       "         -2.8901e-02, -1.8757e-01,  8.9256e-03,  2.0940e-01,  9.0927e-02,\n",
       "         -8.2969e-02, -9.0893e-03,  1.0047e-01, -1.6897e-02, -1.3736e-01,\n",
       "          1.6801e-01, -1.9342e-01, -3.4822e-02,  1.0057e-01,  2.2273e-02],\n",
       "        [ 1.4611e-01,  1.4414e-01, -2.3093e-02,  8.1946e-02,  5.9792e-03,\n",
       "          6.7672e-02,  1.5254e-01,  1.6742e-01, -1.6896e-01,  1.1571e-01,\n",
       "         -1.8538e-01,  2.3316e-02, -1.6147e-01,  1.0230e-01, -1.7314e-01,\n",
       "         -1.8906e-01, -2.0286e-01, -2.1210e-02, -2.1799e-02, -3.7921e-02],\n",
       "        [ 1.9375e-01,  5.3921e-02, -1.4900e-01,  1.6709e-01, -1.6652e-01,\n",
       "          6.2363e-02, -4.1574e-02, -2.0565e-01, -1.3649e-01, -2.0600e-01,\n",
       "         -1.9032e-01, -8.8942e-02, -7.8061e-02,  1.6323e-01, -1.3174e-01,\n",
       "          5.8638e-02,  2.1117e-01,  1.6707e-01, -5.9492e-02, -2.0973e-01],\n",
       "        [-2.5644e-02, -1.0818e-02, -3.3051e-02,  3.7071e-02, -1.0809e-01,\n",
       "          2.0642e-01,  1.2396e-01, -2.1523e-01,  1.2172e-01, -1.4323e-01,\n",
       "          1.1334e-01,  4.6931e-02,  8.4553e-02,  2.0530e-01, -1.1833e-01,\n",
       "          1.9287e-01, -2.8398e-02,  7.1443e-03, -2.1055e-01,  1.0805e-01],\n",
       "        [-1.2258e-01, -6.8325e-02, -2.1929e-01, -1.4939e-01,  1.9226e-01,\n",
       "         -6.2922e-02, -7.6377e-02,  2.1955e-01, -4.5838e-02,  9.8011e-03,\n",
       "         -2.9400e-03, -9.5241e-02, -7.9775e-02, -1.8708e-01,  1.7828e-01,\n",
       "         -1.7552e-01, -1.0328e-01, -1.9697e-02, -1.7449e-01,  2.0408e-02]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x0000028EDCA2BC10>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters() #一次性导出现有神经网络架构下全部的权重和截距"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.3656e-01, -1.3459e-01,  2.1281e-01, -1.7763e-01, -6.8218e-02,\n",
      "         -1.5410e-01,  1.7245e-01,  8.3885e-02, -1.1153e-01, -1.7294e-01,\n",
      "         -1.2947e-01, -4.3138e-02, -1.1413e-01,  1.6295e-01, -9.4082e-02,\n",
      "         -1.4629e-01, -6.8982e-02, -2.1836e-01, -1.0859e-01, -1.2199e-01],\n",
      "        [ 4.8127e-02,  1.8186e-01,  2.4149e-02, -1.3032e-01,  9.2056e-02,\n",
      "         -9.5202e-02, -1.0584e-01, -4.2852e-02, -1.1669e-01,  2.4581e-02,\n",
      "          1.8152e-01,  3.0500e-02,  1.3506e-01, -1.9425e-01, -1.7591e-01,\n",
      "         -2.9751e-02,  2.0485e-04,  1.3957e-01, -1.9666e-01,  9.3293e-02],\n",
      "        [-1.9192e-01,  3.6070e-02,  1.4778e-01,  3.0845e-02,  7.1393e-02,\n",
      "          1.4217e-01,  2.2122e-01, -1.4032e-01,  7.3255e-02,  1.8409e-01,\n",
      "          1.2716e-01, -2.0253e-01, -1.5509e-01, -2.1899e-01,  9.8980e-02,\n",
      "          2.2123e-01, -2.1659e-01,  1.7880e-01, -2.0922e-01, -2.7275e-02],\n",
      "        [ 1.8144e-01, -3.5166e-02,  2.4801e-02,  1.6299e-01, -1.8755e-01,\n",
      "          5.6587e-02, -1.0911e-01,  2.0523e-01, -1.9378e-01,  1.6899e-02,\n",
      "          1.3966e-01, -1.3137e-01, -1.3201e-01,  7.6554e-02, -1.7558e-01,\n",
      "          1.3096e-01,  2.7182e-02, -2.2010e-01,  7.6883e-02, -1.8731e-01],\n",
      "        [ 2.7419e-02,  1.3699e-01, -3.8687e-02,  8.3463e-02, -1.5634e-02,\n",
      "         -1.6781e-01, -2.1426e-01,  1.8463e-01,  8.3891e-02,  5.9950e-02,\n",
      "         -2.0538e-01, -2.7832e-02,  4.7442e-02, -1.9782e-01, -1.7842e-01,\n",
      "          1.1362e-01,  1.4101e-01, -1.3794e-01,  1.1704e-01, -3.4108e-02],\n",
      "        [ 3.8388e-02, -1.7268e-01, -1.0235e-01, -1.2634e-01, -1.1883e-01,\n",
      "         -1.3463e-01, -1.7610e-01,  3.6543e-02, -1.7834e-01, -1.6471e-01,\n",
      "          2.0834e-01,  1.8400e-01, -8.8723e-02, -7.5378e-02,  1.7877e-01,\n",
      "         -5.7259e-02, -2.4522e-02, -1.1822e-02, -1.8196e-01,  1.9812e-01],\n",
      "        [-2.2011e-02,  2.1847e-01,  1.8410e-01,  9.7177e-02, -5.0634e-03,\n",
      "         -2.4731e-03,  5.1408e-03, -2.1733e-01, -5.3375e-02, -1.0346e-01,\n",
      "         -1.3303e-02,  2.7354e-02, -1.7523e-01,  1.6994e-01,  1.8259e-01,\n",
      "          1.3907e-01,  1.0041e-01,  3.5377e-02, -1.6114e-01,  9.0056e-02],\n",
      "        [ 7.9232e-02,  2.1614e-01, -2.1087e-01,  1.9407e-01,  1.7559e-01,\n",
      "          4.1470e-02,  7.4482e-02,  2.6737e-02, -1.7872e-02,  4.5040e-02,\n",
      "          1.2947e-01,  2.5483e-02, -2.0320e-02, -7.3942e-03, -1.7221e-01,\n",
      "         -1.0705e-01,  1.8203e-01,  1.3179e-02,  2.3468e-02, -1.9567e-01],\n",
      "        [ 1.6338e-01,  8.0209e-03, -2.9885e-02, -2.1884e-01,  1.3471e-01,\n",
      "         -2.8901e-02, -1.8757e-01,  8.9256e-03,  2.0940e-01,  9.0927e-02,\n",
      "         -8.2969e-02, -9.0893e-03,  1.0047e-01, -1.6897e-02, -1.3736e-01,\n",
      "          1.6801e-01, -1.9342e-01, -3.4822e-02,  1.0057e-01,  2.2273e-02],\n",
      "        [ 1.4611e-01,  1.4414e-01, -2.3093e-02,  8.1946e-02,  5.9792e-03,\n",
      "          6.7672e-02,  1.5254e-01,  1.6742e-01, -1.6896e-01,  1.1571e-01,\n",
      "         -1.8538e-01,  2.3316e-02, -1.6147e-01,  1.0230e-01, -1.7314e-01,\n",
      "         -1.8906e-01, -2.0286e-01, -2.1210e-02, -2.1799e-02, -3.7921e-02],\n",
      "        [ 1.9375e-01,  5.3921e-02, -1.4900e-01,  1.6709e-01, -1.6652e-01,\n",
      "          6.2363e-02, -4.1574e-02, -2.0565e-01, -1.3649e-01, -2.0600e-01,\n",
      "         -1.9032e-01, -8.8942e-02, -7.8061e-02,  1.6323e-01, -1.3174e-01,\n",
      "          5.8638e-02,  2.1117e-01,  1.6707e-01, -5.9492e-02, -2.0973e-01],\n",
      "        [-2.5644e-02, -1.0818e-02, -3.3051e-02,  3.7071e-02, -1.0809e-01,\n",
      "          2.0642e-01,  1.2396e-01, -2.1523e-01,  1.2172e-01, -1.4323e-01,\n",
      "          1.1334e-01,  4.6931e-02,  8.4553e-02,  2.0530e-01, -1.1833e-01,\n",
      "          1.9287e-01, -2.8398e-02,  7.1443e-03, -2.1055e-01,  1.0805e-01],\n",
      "        [-1.2258e-01, -6.8325e-02, -2.1929e-01, -1.4939e-01,  1.9226e-01,\n",
      "         -6.2922e-02, -7.6377e-02,  2.1955e-01, -4.5838e-02,  9.8011e-03,\n",
      "         -2.9400e-03, -9.5241e-02, -7.9775e-02, -1.8708e-01,  1.7828e-01,\n",
      "         -1.7552e-01, -1.0328e-01, -1.9697e-02, -1.7449e-01,  2.0408e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.3508e-01,  1.5439e-01, -1.9350e-01, -6.8777e-02,  1.3787e-01,\n",
      "        -1.8474e-01,  1.2763e-01,  1.8031e-01,  9.5152e-02, -1.2660e-01,\n",
      "         1.4317e-01, -1.4945e-01,  3.4258e-05], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0854,  0.0825,  0.1020, -0.0941,  0.2054,  0.2645, -0.2198, -0.0169,\n",
      "          0.0017, -0.2714, -0.1154,  0.0410, -0.0668],\n",
      "        [-0.2668,  0.1752, -0.2743,  0.1611, -0.1190,  0.0476,  0.0036,  0.2185,\n",
      "         -0.1021,  0.2397,  0.1055, -0.0704, -0.1420],\n",
      "        [ 0.2249, -0.2563, -0.2121, -0.0678,  0.1129,  0.0035,  0.0988,  0.2494,\n",
      "          0.1891, -0.0448,  0.1583,  0.0126,  0.2220],\n",
      "        [-0.2095, -0.1938, -0.0562, -0.2183, -0.2483,  0.2078,  0.2142,  0.0754,\n",
      "         -0.2532,  0.1142,  0.0657, -0.0808,  0.2725],\n",
      "        [ 0.2063,  0.0870, -0.2641,  0.2648,  0.1443, -0.2759,  0.0101,  0.1611,\n",
      "          0.2489, -0.1175,  0.0537, -0.0365,  0.2095],\n",
      "        [ 0.2333, -0.0148, -0.2440,  0.0268,  0.1815,  0.2528, -0.2730,  0.2145,\n",
      "          0.0205, -0.2279,  0.0727, -0.2309, -0.1754],\n",
      "        [-0.1644, -0.0508,  0.0548,  0.0702, -0.1867, -0.0818,  0.2041, -0.0269,\n",
      "         -0.1098, -0.0464,  0.1511,  0.0050, -0.1364],\n",
      "        [ 0.2180, -0.0104,  0.1469, -0.0562, -0.2288, -0.0920,  0.1706, -0.1874,\n",
      "         -0.1059, -0.0818, -0.2628, -0.2723,  0.1970]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0900, -0.0597,  0.0268, -0.0173,  0.0065,  0.0228, -0.1408,  0.1188],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1259,  0.1116, -0.0097, -0.1100,  0.0427,  0.3335, -0.2140, -0.2908],\n",
      "        [-0.0166,  0.0617, -0.2413,  0.0719, -0.0847, -0.0331, -0.1862,  0.1859],\n",
      "        [-0.1704,  0.1227,  0.3419,  0.0164, -0.2700, -0.0598, -0.2827, -0.3440]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0156, -0.0730, -0.2637], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for x in net.parameters():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(net.parameters()#需要进行迭代的权重\n",
    "                ,lr = lr\n",
    "                ,momentum = gamma\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#向前传播\n",
    "#本轮向前传播的损失函数值\n",
    "#反向传播 - 得到了梯度\n",
    "#更新权重（和动量）\n",
    "#清空梯度 - 清除原来计算出来的，基于上一个点的坐标计算的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 20])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0643, grad_fn=<NllLossBackward>)\n",
      "tensor([ 0.1435, -0.1329,  0.2212, -0.1767, -0.0652, -0.1528,  0.1800,  0.0898,\n",
      "        -0.1094, -0.1720])\n"
     ]
    }
   ],
   "source": [
    "zhat = net.forward(X) #最后一个线性层的输出结果，向前传播\n",
    "loss = criterion(zhat, y.reshape(500).long()) #计算损失函数\n",
    "loss.backward()\n",
    "opt.step() #步子，走一步，更新权重w，更新动量v\n",
    "opt.zero_grad()\n",
    "\n",
    "print(loss)\n",
    "print(net.linear1.weight.data[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoch = 60 #请让神经网络学习60次全部数据\n",
    "#把全数据X划分为10个batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-149-c722bef8e3a0>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-149-c722bef8e3a0>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    for i in ……\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "for epochs in range(epoch):\n",
    "    for batch in range(batch):\n",
    "        zhat = net.forward(X) #最后一个线性层的输出结果，向前传播\n",
    "        loss = criterion(zhat, y.reshape(500).long()) #计算损失函数\n",
    "        loss.backward()\n",
    "        opt.step() #步子，走一步，更新权重w，更新动量v\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(500,2,3) #三维数据 - 二维表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(500,3,4,5) #四维数据 - 图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.randn(500,1) #二维数据 - 标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#被合并的对象第一维度上的值相等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 0.3641,  1.1461,  1.3315, -0.6803, -0.1573],\n",
      "         [-0.3813,  0.0569,  1.4741, -0.2237,  0.4374],\n",
      "         [ 0.4338,  0.7315, -0.2749,  0.0160, -0.2451],\n",
      "         [-0.5867, -0.5889,  1.8905, -0.7718, -1.7899]],\n",
      "\n",
      "        [[-0.4048,  0.7898,  0.3773,  0.7166,  0.0490],\n",
      "         [-0.9121, -0.0489, -0.8179, -1.8548, -0.3418],\n",
      "         [ 0.0873,  0.3071, -0.9272,  1.4546, -0.8360],\n",
      "         [ 1.2235,  1.2197, -0.5222,  0.2297, -0.8180]],\n",
      "\n",
      "        [[ 0.4578, -2.0396, -0.1589, -0.3033, -0.6102],\n",
      "         [ 1.1299,  0.8919, -0.5627,  0.4364, -0.2321],\n",
      "         [ 0.1634,  1.4667, -0.7651, -0.6503,  0.0228],\n",
      "         [ 0.8123,  0.9057,  1.3573, -0.3826,  0.2580]]]), tensor([-0.6932]))\n"
     ]
    }
   ],
   "source": [
    "for x in TensorDataset(b,c):#generator\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoader - 用来切割小批量的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TensorDataset(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[ 0.3641,  1.1461,  1.3315, -0.6803, -0.1573],\n",
      "          [-0.3813,  0.0569,  1.4741, -0.2237,  0.4374],\n",
      "          [ 0.4338,  0.7315, -0.2749,  0.0160, -0.2451],\n",
      "          [-0.5867, -0.5889,  1.8905, -0.7718, -1.7899]],\n",
      "\n",
      "         [[-0.4048,  0.7898,  0.3773,  0.7166,  0.0490],\n",
      "          [-0.9121, -0.0489, -0.8179, -1.8548, -0.3418],\n",
      "          [ 0.0873,  0.3071, -0.9272,  1.4546, -0.8360],\n",
      "          [ 1.2235,  1.2197, -0.5222,  0.2297, -0.8180]],\n",
      "\n",
      "         [[ 0.4578, -2.0396, -0.1589, -0.3033, -0.6102],\n",
      "          [ 1.1299,  0.8919, -0.5627,  0.4364, -0.2321],\n",
      "          [ 0.1634,  1.4667, -0.7651, -0.6503,  0.0228],\n",
      "          [ 0.8123,  0.9057,  1.3573, -0.3826,  0.2580]]]]), tensor([[-0.6932]])]\n"
     ]
    }
   ],
   "source": [
    "for x in DataLoader(data):\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#500 - 120, 120, 120, 120, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataLoader(data\n",
    "          , batch_size = bs\n",
    "          , shuffle = True #划分小批量之前请随机打乱我们的数据\n",
    "          , drop_last = True #你要舍弃最后一个batch吗？\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 3, 4, 5])\n",
      "torch.Size([120, 3, 4, 5])\n",
      "torch.Size([120, 3, 4, 5])\n",
      "torch.Size([120, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset) #一共有多少个batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.dataset) #展示里面全部的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3641,  1.1461,  1.3315, -0.6803, -0.1573],\n",
       "          [-0.3813,  0.0569,  1.4741, -0.2237,  0.4374],\n",
       "          [ 0.4338,  0.7315, -0.2749,  0.0160, -0.2451],\n",
       "          [-0.5867, -0.5889,  1.8905, -0.7718, -1.7899]],\n",
       " \n",
       "         [[-0.4048,  0.7898,  0.3773,  0.7166,  0.0490],\n",
       "          [-0.9121, -0.0489, -0.8179, -1.8548, -0.3418],\n",
       "          [ 0.0873,  0.3071, -0.9272,  1.4546, -0.8360],\n",
       "          [ 1.2235,  1.2197, -0.5222,  0.2297, -0.8180]],\n",
       " \n",
       "         [[ 0.4578, -2.0396, -0.1589, -0.3033, -0.6102],\n",
       "          [ 1.1299,  0.8919, -0.5627,  0.4364, -0.2321],\n",
       "          [ 0.1634,  1.4667, -0.7651, -0.6503,  0.0228],\n",
       "          [ 0.8123,  0.9057,  1.3573, -0.3826,  0.2580]]]),\n",
       " tensor([-0.6932]))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset[0] #单个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3641,  1.1461,  1.3315, -0.6803, -0.1573],\n",
       "         [-0.3813,  0.0569,  1.4741, -0.2237,  0.4374],\n",
       "         [ 0.4338,  0.7315, -0.2749,  0.0160, -0.2451],\n",
       "         [-0.5867, -0.5889,  1.8905, -0.7718, -1.7899]],\n",
       "\n",
       "        [[-0.4048,  0.7898,  0.3773,  0.7166,  0.0490],\n",
       "         [-0.9121, -0.0489, -0.8179, -1.8548, -0.3418],\n",
       "         [ 0.0873,  0.3071, -0.9272,  1.4546, -0.8360],\n",
       "         [ 1.2235,  1.2197, -0.5222,  0.2297, -0.8180]],\n",
       "\n",
       "        [[ 0.4578, -2.0396, -0.1589, -0.3033, -0.6102],\n",
       "         [ 1.1299,  0.8919, -0.5627,  0.4364, -0.2321],\n",
       "         [ 0.1634,  1.4667, -0.7651, -0.6503,  0.0228],\n",
       "         [ 0.8123,  0.9057,  1.3573, -0.3826,  0.2580]]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6932])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.batch_size #查看现有的batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorDataset - 将特征与标签合并到同一个对象中\n",
    "#DataLoader - 帮助我们进行小批量的分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epochs in range(epoch): #每一个epoch下面进行batch循环\n",
    "    for x,y in #DataLoader生成的对象:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#带大家认识fashion-MINST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms #处理数据模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader、TensorDataset - 对数据的结构、归纳方式进行变换\n",
    "#torchvision.transforms - 对数据集的数字本身进行修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = torchvision.datasets.FashionMNIST(root = \"D:\\Pythonwork\\DEEP LEARNING\\Datasets\\FashionMNIST\" #你的计算机上的某个目录\n",
    "                                          ,download = False\n",
    "                                          , train = True\n",
    "                                          , transform = transforms.ToTensor()\n",
    "                                         ) #实例化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Split: train\n",
       "    Root Location: D:\\Pythonwork\\DEEP LEARNING\\Datasets\\FashionMNIST\n",
       "    Transforms (if any): ToTensor()\n",
       "    Target Transforms (if any): None"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist #对于数据的一个说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape #特征张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[60000,1,28,28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(sample_size, H- height, W - width, C - color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.targets.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist[0][0].view(28,28).numpy()); #imageshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist[1][0].view(28,28).numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist[30001][0].view(28,28).numpy());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TensorDataset 不需要\n",
    "#小批量的划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#确定数据、确定超参数\n",
    "\n",
    "lr = 0.15\n",
    "gamma = 0\n",
    "epochs = 10\n",
    "bs = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = torchvision.datasets.FashionMNIST(root = \"D:\\Pythonwork\\DEEP LEARNING\\Datasets\\FashionMNIST\" #你的计算机上的某个目录\n",
    "                                          ,download = False\n",
    "                                          , train = True\n",
    "                                          , transform = transforms.ToTensor()\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#放入进行迭代的数据结构是什么样的？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchdata = DataLoader(mnist\n",
    "                       ,batch_size = bs\n",
    "                       ,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for x,y in batchdata:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(500,20) - 20\n",
    "#x - 四维 （128,28*28）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = mnist.data[0].numel() #请问这个张量中总共有多少元素呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ = len(mnist.targets.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义神经网络的架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features=10, out_features=2):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features,1280,bias=False)\n",
    "        self.output = nn.Linear(1280,out_features, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,28*28)\n",
    "        sigma1 = torch.relu(self.linear1(x))\n",
    "        sigma2 = F.log_softmax(self.output(sigma1),dim=1)\n",
    "        return sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view(-1,) #需要对数据结构进行一个改变，-1作为占位符，表示请pytorch帮助我们自动计算-1这个位置的维度应是多少"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(30,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(-1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 20])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数、优化算法、梯度下降的流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一个训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.752"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "469/125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batchdata)-1 #469个batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net,bacthdata,lr=0.01, epochs=5, gamma = 0):\n",
    "    criterion = nn.NLLLoss()\n",
    "    opt = optim.SGD(net.parameters(),lr=lr,momentum = gamma)\n",
    "    correct = 0 #循环开始之前，预测正确的值为0\n",
    "    samples = 0 #循环开始之前，模型一个样本都没有见过\n",
    "    for epoch in range(epochs): #全数据被训练几次\n",
    "        for batch_idx,(x,y) in enumerate(batchdata):\n",
    "            y = y.view(x.shape[0]) #降维\n",
    "            sigma = net.forward(x) #正向传播\n",
    "            loss = criterion(sigma,y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            #求解准确率，全部判断正确的样本数量/已经看过的总样本量\n",
    "            yhat = torch.max(sigma, 1)[1] #torch.max函数结果中的索引为1的部分\n",
    "            correct += torch.sum(yhat == y)\n",
    "            samples += x.shape[0]\n",
    "            #每训练一个batch的数据，模型见过的数据就会增加x.shape[0]\n",
    "            \n",
    "            if (batch_idx + 1) % 125 == 0 or batch_idx == len(batchdata)-1: #每N个batch我就打印一次\n",
    "                print(\"Epoch{}:[{}/{}({:.0f}%)],Loss:{:.6f},Accuracy:{:.3f}\".format(\n",
    "                    epoch+1\n",
    "                    ,samples\n",
    "                    ,epochs*len(batchdata.dataset)\n",
    "                    ,100*samples/(epochs*len(batchdata.dataset))\n",
    "                    ,loss.data.item()\n",
    "                    ,float(100*correct/samples)\n",
    "                     ))\n",
    "            #分子代表：已经查看过的数据有多少\n",
    "            #分母代表：在现有的epochs设置，模型一共需要查看多少数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实验一下，这里是值A\n"
     ]
    }
   ],
   "source": [
    "print(\"实验一下，这里是值{}\".format(\"A\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [\"A\",\"B\",\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'A')\n",
      "(1, 'B')\n",
      "(2, 'C')\n"
     ]
    }
   ],
   "source": [
    "for x in enumerate(list):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.tensor([[0.3,0.4,0.25],[0.7,0.2,0.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 0.4000, 0.2500],\n",
       "        [0.7000, 0.2000, 0.1000]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(l,1)[1] #softmax的预测标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.tensor([True,False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(l) #True = 1, False = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1:[16000/600000(3%)],Loss:0.727888,Accuracy:68.819\n",
      "Epoch1:[32000/600000(5%)],Loss:0.513726,Accuracy:73.550\n",
      "Epoch1:[48000/600000(8%)],Loss:0.459364,Accuracy:76.173\n",
      "Epoch1:[60000/600000(10%)],Loss:0.563562,Accuracy:77.373\n",
      "Epoch2:[76000/600000(13%)],Loss:0.433777,Accuracy:78.687\n",
      "Epoch2:[92000/600000(15%)],Loss:0.363204,Accuracy:79.634\n",
      "Epoch2:[108000/600000(18%)],Loss:0.443800,Accuracy:80.304\n",
      "Epoch2:[120000/600000(20%)],Loss:0.442278,Accuracy:80.723\n",
      "Epoch3:[136000/600000(23%)],Loss:0.543707,Accuracy:81.285\n",
      "Epoch3:[152000/600000(25%)],Loss:0.354620,Accuracy:81.691\n",
      "Epoch3:[168000/600000(28%)],Loss:0.526626,Accuracy:82.088\n",
      "Epoch3:[180000/600000(30%)],Loss:0.411618,Accuracy:82.367\n",
      "Epoch4:[196000/600000(33%)],Loss:0.350448,Accuracy:82.678\n",
      "Epoch4:[212000/600000(35%)],Loss:0.345022,Accuracy:83.008\n",
      "Epoch4:[228000/600000(38%)],Loss:0.474553,Accuracy:83.263\n",
      "Epoch4:[240000/600000(40%)],Loss:0.324190,Accuracy:83.479\n",
      "Epoch5:[256000/600000(43%)],Loss:0.317327,Accuracy:83.738\n",
      "Epoch5:[272000/600000(45%)],Loss:0.369660,Accuracy:83.957\n",
      "Epoch5:[288000/600000(48%)],Loss:0.341690,Accuracy:84.139\n",
      "Epoch5:[300000/600000(50%)],Loss:0.547992,Accuracy:84.282\n",
      "Epoch6:[316000/600000(53%)],Loss:0.292443,Accuracy:84.497\n",
      "Epoch6:[332000/600000(55%)],Loss:0.276111,Accuracy:84.649\n",
      "Epoch6:[348000/600000(58%)],Loss:0.318102,Accuracy:84.797\n",
      "Epoch6:[360000/600000(60%)],Loss:0.308750,Accuracy:84.874\n",
      "Epoch7:[376000/600000(63%)],Loss:0.261769,Accuracy:85.029\n",
      "Epoch7:[392000/600000(65%)],Loss:0.467604,Accuracy:85.163\n",
      "Epoch7:[408000/600000(68%)],Loss:0.374349,Accuracy:85.302\n",
      "Epoch7:[420000/600000(70%)],Loss:0.374845,Accuracy:85.384\n",
      "Epoch8:[436000/600000(73%)],Loss:0.292379,Accuracy:85.498\n",
      "Epoch8:[452000/600000(75%)],Loss:0.274055,Accuracy:85.624\n",
      "Epoch8:[468000/600000(78%)],Loss:0.326614,Accuracy:85.734\n",
      "Epoch8:[480000/600000(80%)],Loss:0.377757,Accuracy:85.793\n",
      "Epoch9:[496000/600000(83%)],Loss:0.345958,Accuracy:85.884\n",
      "Epoch9:[512000/600000(85%)],Loss:0.334107,Accuracy:85.993\n",
      "Epoch9:[528000/600000(88%)],Loss:0.161249,Accuracy:86.080\n",
      "Epoch9:[540000/600000(90%)],Loss:0.305421,Accuracy:86.151\n",
      "Epoch10:[556000/600000(93%)],Loss:0.309134,Accuracy:86.249\n",
      "Epoch10:[572000/600000(95%)],Loss:0.341859,Accuracy:86.330\n",
      "Epoch10:[588000/600000(98%)],Loss:0.308504,Accuracy:86.419\n",
      "Epoch10:[600000/600000(100%)],Loss:0.214857,Accuracy:86.484\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(420)\n",
    "net = Model(in_features=input_, out_features=output_)\n",
    "fit(net,batchdata,lr=lr,epochs=epochs,gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
